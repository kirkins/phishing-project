{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #1\n",
    "\n",
    "Get the first dataset with 30 attributes plus result from R. M. Mohammad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
       "0                 -1           1                   1                 1   \n",
       "1                  1           1                   1                 1   \n",
       "2                  1           0                   1                 1   \n",
       "3                  1           0                   1                 1   \n",
       "4                  1           0                  -1                 1   \n",
       "5                 -1           0                  -1                 1   \n",
       "6                  1           0                  -1                 1   \n",
       "7                  1           0                   1                 1   \n",
       "8                  1           0                  -1                 1   \n",
       "9                  1           1                  -1                 1   \n",
       "\n",
       "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
       "0                        -1             -1                 -1              -1   \n",
       "1                         1             -1                  0               1   \n",
       "2                         1             -1                 -1              -1   \n",
       "3                         1             -1                 -1              -1   \n",
       "4                         1             -1                  1               1   \n",
       "5                        -1             -1                  1               1   \n",
       "6                         1             -1                 -1              -1   \n",
       "7                         1             -1                 -1              -1   \n",
       "8                         1             -1                  1               1   \n",
       "9                         1             -1                 -1               1   \n",
       "\n",
       "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
       "0                           -1        1  ...            1       1   \n",
       "1                           -1        1  ...            1       1   \n",
       "2                           -1        1  ...            1       1   \n",
       "3                            1        1  ...            1       1   \n",
       "4                           -1        1  ...           -1       1   \n",
       "5                           -1        1  ...            1       1   \n",
       "6                            1        1  ...            1       1   \n",
       "7                            1        1  ...            1       1   \n",
       "8                           -1        1  ...            1       1   \n",
       "9                           -1        1  ...            1       1   \n",
       "\n",
       "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
       "0             -1         -1           -1         -1             1   \n",
       "1             -1         -1            0         -1             1   \n",
       "2              1         -1            1         -1             1   \n",
       "3             -1         -1            1         -1             1   \n",
       "4             -1         -1            0         -1             1   \n",
       "5              1          1            1         -1             1   \n",
       "6              1         -1           -1         -1             1   \n",
       "7             -1         -1            0         -1             1   \n",
       "8              1         -1            1          1             1   \n",
       "9              1         -1            0         -1             1   \n",
       "\n",
       "   Links_pointing_to_page  Statistical_report  Result  \n",
       "0                       1                  -1      -1  \n",
       "1                       1                   1      -1  \n",
       "2                       0                  -1      -1  \n",
       "3                      -1                   1      -1  \n",
       "4                       1                   1       1  \n",
       "5                      -1                  -1       1  \n",
       "6                       0                  -1      -1  \n",
       "7                       0                   1      -1  \n",
       "8                       0                   1       1  \n",
       "9                       0                   1      -1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url=\"./Phishing.csv\"\n",
    "df=pd.read_csv(url)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #1. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #1 : 11055\n",
      "Column count for dataset #1 : 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #1 :\", str(df.shape[0]))\n",
    "print(\"Column count for dataset #1 :\", str(df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #2\n",
    "\n",
    "Get the second dataset with 111 attributes plus result from Vrbančič."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0            3               0                  0              1   \n",
       "1            5               0                  1              3   \n",
       "2            2               0                  0              1   \n",
       "3            4               0                  2              5   \n",
       "4            2               0                  0              0   \n",
       "5            1               0                  0              2   \n",
       "6            2               0                  0              0   \n",
       "7            2               0                  0              3   \n",
       "8            2               0                  0              0   \n",
       "9            1               0                  0              2   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              3           0            2   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "5                     0              0           0            0   \n",
       "6                     0              0           0            0   \n",
       "7                     0              0           0            0   \n",
       "8                     0              0           0            0   \n",
       "9                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  qty_nameservers  \\\n",
       "0                    0              0  ...                1                2   \n",
       "1                    0              0  ...                1                2   \n",
       "2                    0              0  ...                1                2   \n",
       "3                    0              0  ...                1                2   \n",
       "4                    0              0  ...                1                2   \n",
       "5                    0              0  ...                1                3   \n",
       "6                    0              0  ...                1                2   \n",
       "7                    0              0  ...                1                2   \n",
       "8                    0              0  ...                1                4   \n",
       "9                    0              0  ...                1                2   \n",
       "\n",
       "   qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0               0           892                    0              0   \n",
       "1               1          9540                    1              0   \n",
       "2               3           589                    1              0   \n",
       "3               0           292                    1              0   \n",
       "4               1          3597                    0              1   \n",
       "5               3          3591                    1              0   \n",
       "6               2           291                    0              0   \n",
       "7               1          3134                    1              0   \n",
       "8               2          3596                    1              1   \n",
       "9               1         14397                    1              0   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  \n",
       "5                 0                    0              0         1  \n",
       "6                 0                    0              0         0  \n",
       "7                 0                    0              0         0  \n",
       "8                 0                    0              0         0  \n",
       "9                 0                    0              0         1  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2=\"https://raw.githubusercontent.com/GregaVrbancic/Phishing-Dataset/master/vrbancic_phishing_dataset.csv\"\n",
    "df2=pd.read_csv(url2)\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #2. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #2 : 88647\n",
      "Column count for dataset #2 : 111\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #2 :\", str(df2.shape[0]))\n",
    "print(\"Column count for dataset #2 :\", str(df2.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "On the first dataset convert value of -1 to 0 for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Result'].values[df['Result'].values < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will replace any missing values with the mean value for that column. This will be done for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use mean value for any nan values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df2.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split both of our datasets into section for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data up into training and test data\n",
    "x = df.iloc[:,0:30].values.astype(int)\n",
    "y = df.iloc[:,30].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x2 = df2.iloc[:,0:111].values.astype(int)\n",
    "y2 = df2.iloc[:,111].values.astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Baseline Result\n",
    "\n",
    "Import `numpy` and set a random seed so that random values will be the same each time we run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a baseline comparision for our neural network we'll do a round of logitstic regression with a maximum iteration of 10,000. We'll use our training and test set from each dataset to get an accuracy score for both datasets while using logistic regression.\n",
    "\n",
    "This will be the baseline value to beat when using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr2 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "logisticRegr2.fit(x_train2, y_train2)\n",
    "\n",
    "y_pred=logisticRegr.predict(x_test)\n",
    "y_pred2=logisticRegr2.predict(x_test2)\n",
    "\n",
    "t = precision_recall_fscore_support(y_test, logisticRegr.predict(x_test), average='micro')\n",
    "t2 = precision_recall_fscore_support(y_test2, logisticRegr2.predict(x_test2), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9240162822252375\n",
      "Precision: 0.9276160503540519\n",
      "Recall: 0.9394422310756972\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9217146080090243\n",
      "Precision: 0.8633988936693301\n",
      "Recall: 0.9184373978424322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision:\",metrics.precision_score(y_test2, y_pred2))\n",
    "print(\"Recall:\",metrics.recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Next we'll move to using our same datasets with a neural network. We're using 2 different rectified linear unit layers each with a slightly different amount of neurons. The results from these 2 layers arrives sequentially at the last layer sigmoid which produces a prediction. The sigmoid layer always produces a value between 0 and 1 which is useful in making our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# This model actually seems to work better with higher numbers\n",
    "model.add(Dense(30, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model.add(Dense(40, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #1\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "30 | 40 | 1 | 95.52%\n",
    "40 | 30 | 1 | 91.30%\n",
    "30 | 50 | 1 | 91.30%\n",
    "40 | 50 | 1 | 95.66%\n",
    "50 | 60 | 1 | 96.20%\n",
    "60 | 70 | 1 | 91.30%\n",
    "100 | 120 | 1 | 96.25%\n",
    "200 | 240 | 1 | 96.47%\n",
    "**400** | **480** | **1** | **96.88%**\n",
    "800 | 960 | 1 | 96.70%\n",
    "1200 | 1300 | 1 | 91.30%\n",
    "1600 | 1920 | 1 | 96.79%\n",
    "3200 | 3840 | 1 | 96.83%\n",
    "6400 | 7680 | 1 | 96.61%\n",
    "6900 | 7680 | 1 | 96.38%\n",
    "12800 | 15360 | 1 | 96.11%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 2,211\n",
      "Trainable params: 2,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #2\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "135 | 111 | 1 | 92.55%\n",
    "145 | 111 | 1 | 92.30%\n",
    "270 | 222 | 1 | 93.73%\n",
    "540 | 444 | 1 | 91.84%\n",
    "600 | 450 | 1 | 92.79%\n",
    "600 | 500 | 1 | 92.24%\n",
    "135 | 135 | 1 | 93.16%\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "111 | 135 | 1 | 92.70%\n",
    "222 | 270 | 1 | 93.18%\n",
    "450 | 600 | 1 | 93.53%\n",
    "666 | 777 | 1 | 91.89%\n",
    "900 | 1200 | 1 | 93.13%\n",
    "\n",
    "Trying with 2 instead of 3 layers.\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | --- \n",
    "135 | 1 | 93.05\n",
    "\n",
    "\n",
    "Trying with 4 instead of 3 layers.\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | Accuracy\n",
    "--- | --- | --- | --- | ---\n",
    "111 | 111 | 111 | 1 | 93.46%\n",
    "135 | 135 | 135 | 1 | 93.92%\n",
    "270 | 222 | 135 | 1 | 93.38%\n",
    "166 | 166 | 166 | 1 | 93.72%\n",
    "270 | 270 | 270 | 1 | 93.65%\n",
    "600 | 270 | 135 | 1 | 92.60%\n",
    "888 | 888 | 888 | 1 | 93.31%\n",
    "160 | 150 | 140 | 1 | 93.59%\n",
    "140 | 140 | 140 | 1 | 93.79%\n",
    "130 | 130 | 130 | 1 | 92.99%\n",
    "135 | 270 | 600 | 1 | 93.55%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building using the Sequential API\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(900, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x2.shape[1]))\n",
    "model2.add(Dense(1200, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 111)               12432     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 135)               15120     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 136       \n",
      "=================================================================\n",
      "Total params: 27,688\n",
      "Trainable params: 27,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "es_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 10s 1ms/step - loss: 0.1860 - accuracy: 0.9239\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 10s 1ms/step - loss: 0.1295 - accuracy: 0.9448\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 10s 1ms/step - loss: 0.1129 - accuracy: 0.9523\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 10s 1ms/step - loss: 0.0988 - accuracy: 0.9569\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 10s 1ms/step - loss: 0.0908 - accuracy: 0.9603\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 11s 1ms/step - loss: 0.0797 - accuracy: 0.9661\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 11s 1ms/step - loss: 0.0724 - accuracy: 0.9704\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 11s 1ms/step - loss: 0.0663 - accuracy: 0.9717\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 19s 2ms/step - loss: 0.0659 - accuracy: 0.9738\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0610 - accuracy: 0.9755\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 20s 2ms/step - loss: 0.0606 - accuracy: 0.9747\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 20s 2ms/step - loss: 0.0586 - accuracy: 0.9749\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 20s 2ms/step - loss: 0.0522 - accuracy: 0.9775\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0487 - accuracy: 0.9790\n",
      "Epoch 15/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0461 - accuracy: 0.9801\n",
      "Epoch 16/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0482 - accuracy: 0.9789\n",
      "Epoch 17/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0422 - accuracy: 0.9806\n",
      "Epoch 18/128\n",
      "8844/8844 [==============================] - 20s 2ms/step - loss: 0.0398 - accuracy: 0.9817\n",
      "Epoch 19/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0398 - accuracy: 0.9825\n",
      "Epoch 20/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0491 - accuracy: 0.9776\n",
      "Epoch 21/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0519 - accuracy: 0.9801\n",
      "Epoch 22/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0433 - accuracy: 0.9812\n",
      "Epoch 23/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0344 - accuracy: 0.9859\n",
      "Epoch 24/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0329 - accuracy: 0.9850\n",
      "Epoch 25/128\n",
      "8844/8844 [==============================] - 23s 3ms/step - loss: 0.0341 - accuracy: 0.9847\n",
      "Epoch 26/128\n",
      "8844/8844 [==============================] - 21s 2ms/step - loss: 0.0374 - accuracy: 0.9830\n",
      "Epoch 27/128\n",
      "8844/8844 [==============================] - 22s 3ms/step - loss: 0.0367 - accuracy: 0.9833\n",
      "Epoch 28/128\n",
      "8844/8844 [==============================] - 22s 2ms/step - loss: 0.0326 - accuracy: 0.9855\n",
      "Epoch 29/128\n",
      "8844/8844 [==============================] - 31s 4ms/step - loss: 0.0325 - accuracy: 0.9854\n",
      "2211/2211 [==============================] - 3s 2ms/step\n",
      "\n",
      "Accuracy score of the Neural Network with basic hyperparameter settings 96.79%\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with basic hyperparameter settings {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "70917/70917 [==============================] - 36s 509us/step - loss: 22.7203 - accuracy: 0.7693\n",
      "Epoch 2/128\n",
      "70917/70917 [==============================] - 35s 495us/step - loss: 0.5406 - accuracy: 0.8703\n",
      "Epoch 3/128\n",
      "70917/70917 [==============================] - 35s 497us/step - loss: 0.3450 - accuracy: 0.8854\n",
      "Epoch 4/128\n",
      "70917/70917 [==============================] - 38s 534us/step - loss: 0.2486 - accuracy: 0.9033\n",
      "Epoch 5/128\n",
      "70917/70917 [==============================] - 40s 558us/step - loss: 0.2465 - accuracy: 0.9025\n",
      "Epoch 6/128\n",
      "70917/70917 [==============================] - 39s 553us/step - loss: 0.2553 - accuracy: 0.9014\n",
      "Epoch 7/128\n",
      "70917/70917 [==============================] - 42s 587us/step - loss: 0.2273 - accuracy: 0.9066\n",
      "Epoch 8/128\n",
      "70917/70917 [==============================] - 75s 1ms/step - loss: 0.2424 - accuracy: 0.9033\n",
      "Epoch 9/128\n",
      "70917/70917 [==============================] - 80s 1ms/step - loss: 0.2131 - accuracy: 0.9104\n",
      "Epoch 10/128\n",
      "70917/70917 [==============================] - 75s 1ms/step - loss: 0.2168 - accuracy: 0.9102\n",
      "Epoch 11/128\n",
      "70917/70917 [==============================] - 69s 979us/step - loss: 0.2179 - accuracy: 0.9116\n",
      "Epoch 12/128\n",
      "70917/70917 [==============================] - 78s 1ms/step - loss: 0.2028 - accuracy: 0.9153\n",
      "Epoch 13/128\n",
      "70917/70917 [==============================] - 79s 1ms/step - loss: 0.2010 - accuracy: 0.9164\n",
      "Epoch 14/128\n",
      "70917/70917 [==============================] - 77s 1ms/step - loss: 0.1998 - accuracy: 0.9157\n",
      "Epoch 15/128\n",
      "70917/70917 [==============================] - 74s 1ms/step - loss: 0.1943 - accuracy: 0.9180\n",
      "Epoch 16/128\n",
      "70917/70917 [==============================] - 77s 1ms/step - loss: 0.1934 - accuracy: 0.9199\n",
      "Epoch 17/128\n",
      "70917/70917 [==============================] - 63s 886us/step - loss: 0.1945 - accuracy: 0.9185\n",
      "Epoch 18/128\n",
      "70917/70917 [==============================] - 59s 833us/step - loss: 0.1926 - accuracy: 0.9192\n",
      "Epoch 19/128\n",
      "70917/70917 [==============================] - 72s 1ms/step - loss: 0.1918 - accuracy: 0.9197\n",
      "Epoch 20/128\n",
      "70917/70917 [==============================] - 77s 1ms/step - loss: 0.1957 - accuracy: 0.9188\n",
      "Epoch 21/128\n",
      "70917/70917 [==============================] - 75s 1ms/step - loss: 0.1894 - accuracy: 0.9205\n",
      "Epoch 22/128\n",
      "70917/70917 [==============================] - 85s 1ms/step - loss: 0.1895 - accuracy: 0.9208\n",
      "Epoch 23/128\n",
      "70917/70917 [==============================] - 65s 914us/step - loss: 0.1894 - accuracy: 0.9214\n",
      "Epoch 24/128\n",
      "70917/70917 [==============================] - 78s 1ms/step - loss: 0.1888 - accuracy: 0.9223\n",
      "Epoch 25/128\n",
      "70917/70917 [==============================] - 79s 1ms/step - loss: 0.1895 - accuracy: 0.9219\n",
      "Epoch 26/128\n",
      "70917/70917 [==============================] - 72s 1ms/step - loss: 0.1850 - accuracy: 0.9224\n",
      "Epoch 27/128\n",
      "70917/70917 [==============================] - 75s 1ms/step - loss: 0.1808 - accuracy: 0.9245\n",
      "Epoch 28/128\n",
      "70917/70917 [==============================] - 76s 1ms/step - loss: 0.1799 - accuracy: 0.9251\n",
      "Epoch 29/128\n",
      "70917/70917 [==============================] - 86s 1ms/step - loss: 0.1806 - accuracy: 0.9245\n",
      "Epoch 30/128\n",
      "70917/70917 [==============================] - 90s 1ms/step - loss: 0.1821 - accuracy: 0.9248\n",
      "Epoch 31/128\n",
      "70917/70917 [==============================] - 85s 1ms/step - loss: 0.1801 - accuracy: 0.9249\n",
      "Epoch 32/128\n",
      "70917/70917 [==============================] - 89s 1ms/step - loss: 0.1907 - accuracy: 0.9223\n",
      "17730/17730 [==============================] - 4s 220us/step\n",
      "\n",
      "Accuracy score of the Neural Network with basic hyperparameter settings 93.13%\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train2, y_train2, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores2 = model2.evaluate(x_test2, y_test2)\n",
    "print('\\nAccuracy score of the Neural Network with basic hyperparameter settings {0:.2f}%'.format(scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TDLHBA hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(135, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=111))\n",
    "model_TDLHBA.add(Dense(111, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.0017470)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 135)               4185      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 111)               15096     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 112       \n",
      "=================================================================\n",
      "Total params: 19,393\n",
      "Trainable params: 19,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_4_input to have shape (111,) but got array with shape (30,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-f0a5ffd45699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_TDLHBA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_TDLHBA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_TDLHBA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nAccuracy score of the Neural Network with TDLHBA hyperparameter settings {0:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1152\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 579\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    580\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    143\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    146\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_4_input to have shape (111,) but got array with shape (30,)"
     ]
    }
   ],
   "source": [
    "history_TDLHBA = model_TDLHBA.fit(x_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model_TDLHBA.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with TDLHBA hyperparameter settings {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
