{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #1\n",
    "\n",
    "Get the first dataset with 30 attributes plus result from R. M. Mohammad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
       "0                 -1           1                   1                 1   \n",
       "1                  1           1                   1                 1   \n",
       "2                  1           0                   1                 1   \n",
       "3                  1           0                   1                 1   \n",
       "4                  1           0                  -1                 1   \n",
       "5                 -1           0                  -1                 1   \n",
       "6                  1           0                  -1                 1   \n",
       "7                  1           0                   1                 1   \n",
       "8                  1           0                  -1                 1   \n",
       "9                  1           1                  -1                 1   \n",
       "\n",
       "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
       "0                        -1             -1                 -1              -1   \n",
       "1                         1             -1                  0               1   \n",
       "2                         1             -1                 -1              -1   \n",
       "3                         1             -1                 -1              -1   \n",
       "4                         1             -1                  1               1   \n",
       "5                        -1             -1                  1               1   \n",
       "6                         1             -1                 -1              -1   \n",
       "7                         1             -1                 -1              -1   \n",
       "8                         1             -1                  1               1   \n",
       "9                         1             -1                 -1               1   \n",
       "\n",
       "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
       "0                           -1        1  ...            1       1   \n",
       "1                           -1        1  ...            1       1   \n",
       "2                           -1        1  ...            1       1   \n",
       "3                            1        1  ...            1       1   \n",
       "4                           -1        1  ...           -1       1   \n",
       "5                           -1        1  ...            1       1   \n",
       "6                            1        1  ...            1       1   \n",
       "7                            1        1  ...            1       1   \n",
       "8                           -1        1  ...            1       1   \n",
       "9                           -1        1  ...            1       1   \n",
       "\n",
       "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
       "0             -1         -1           -1         -1             1   \n",
       "1             -1         -1            0         -1             1   \n",
       "2              1         -1            1         -1             1   \n",
       "3             -1         -1            1         -1             1   \n",
       "4             -1         -1            0         -1             1   \n",
       "5              1          1            1         -1             1   \n",
       "6              1         -1           -1         -1             1   \n",
       "7             -1         -1            0         -1             1   \n",
       "8              1         -1            1          1             1   \n",
       "9              1         -1            0         -1             1   \n",
       "\n",
       "   Links_pointing_to_page  Statistical_report  Result  \n",
       "0                       1                  -1      -1  \n",
       "1                       1                   1      -1  \n",
       "2                       0                  -1      -1  \n",
       "3                      -1                   1      -1  \n",
       "4                       1                   1       1  \n",
       "5                      -1                  -1       1  \n",
       "6                       0                  -1      -1  \n",
       "7                       0                   1      -1  \n",
       "8                       0                   1       1  \n",
       "9                       0                   1      -1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url=\"./Phishing.csv\"\n",
    "df=pd.read_csv(url)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #1. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #1 : 11055\n",
      "Column count for dataset #1 : 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #1 :\", str(df.shape[0]))\n",
    "print(\"Column count for dataset #1 :\", str(df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #2\n",
    "\n",
    "Get the second dataset with 111 attributes plus result from Vrbančič."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0            3               0                  0              1   \n",
       "1            5               0                  1              3   \n",
       "2            2               0                  0              1   \n",
       "3            4               0                  2              5   \n",
       "4            2               0                  0              0   \n",
       "5            1               0                  0              2   \n",
       "6            2               0                  0              0   \n",
       "7            2               0                  0              3   \n",
       "8            2               0                  0              0   \n",
       "9            1               0                  0              2   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              3           0            2   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "5                     0              0           0            0   \n",
       "6                     0              0           0            0   \n",
       "7                     0              0           0            0   \n",
       "8                     0              0           0            0   \n",
       "9                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  qty_nameservers  \\\n",
       "0                    0              0  ...                1                2   \n",
       "1                    0              0  ...                1                2   \n",
       "2                    0              0  ...                1                2   \n",
       "3                    0              0  ...                1                2   \n",
       "4                    0              0  ...                1                2   \n",
       "5                    0              0  ...                1                3   \n",
       "6                    0              0  ...                1                2   \n",
       "7                    0              0  ...                1                2   \n",
       "8                    0              0  ...                1                4   \n",
       "9                    0              0  ...                1                2   \n",
       "\n",
       "   qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0               0           892                    0              0   \n",
       "1               1          9540                    1              0   \n",
       "2               3           589                    1              0   \n",
       "3               0           292                    1              0   \n",
       "4               1          3597                    0              1   \n",
       "5               3          3591                    1              0   \n",
       "6               2           291                    0              0   \n",
       "7               1          3134                    1              0   \n",
       "8               2          3596                    1              1   \n",
       "9               1         14397                    1              0   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  \n",
       "5                 0                    0              0         1  \n",
       "6                 0                    0              0         0  \n",
       "7                 0                    0              0         0  \n",
       "8                 0                    0              0         0  \n",
       "9                 0                    0              0         1  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2=\"https://raw.githubusercontent.com/GregaVrbancic/Phishing-Dataset/master/vrbancic_phishing_dataset.csv\"\n",
    "df2=pd.read_csv(url2)\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #2. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #2 : 88647\n",
      "Column count for dataset #2 : 111\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #2 :\", str(df2.shape[0]))\n",
    "print(\"Column count for dataset #2 :\", str(df2.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #3\n",
    "\n",
    "TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "On the first dataset convert value of -1 to 0 for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Result'].values[df['Result'].values < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will replace any missing values with the mean value for that column. This will be done for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use mean value for any nan values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df2.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split both of our datasets into section for training and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data up into training and test data\n",
    "x = df.iloc[:,0:30].values.astype(int)\n",
    "y = df.iloc[:,30].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x2 = df2.iloc[:,0:111].values.astype(int)\n",
    "y2 = df2.iloc[:,111].values.astype(int)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Baseline Result\n",
    "\n",
    "Import `numpy` and set a random seed so that random values will be the same each time we run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a baseline comparision for our neural network we'll do a round of logitstic regression with a maximum iteration of 10,000. We'll use our training and test set from each dataset to get an accuracy score for both datasets while using logistic regression.\n",
    "\n",
    "This will be the baseline value to beat when using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr2 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "logisticRegr2.fit(x_train2, y_train2)\n",
    "\n",
    "y_pred=logisticRegr.predict(x_test)\n",
    "y_pred2=logisticRegr2.predict(x_test2)\n",
    "\n",
    "t = precision_recall_fscore_support(y_test, logisticRegr.predict(x_test), average='micro')\n",
    "t2 = precision_recall_fscore_support(y_test2, logisticRegr2.predict(x_test2), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9240162822252375\n",
      "Precision: 0.9276160503540519\n",
      "Recall: 0.9394422310756972\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9217146080090243\n",
      "Precision: 0.8633988936693301\n",
      "Recall: 0.9184373978424322\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision:\",metrics.precision_score(y_test2, y_pred2))\n",
    "print(\"Recall:\",metrics.recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Next we'll move to using our same datasets with a neural network. We're using 2 different rectified linear unit layers each with a slightly different amount of neurons. The results from these 2 layers arrives sequentially at the last layer sigmoid which produces a prediction. The sigmoid layer always produces a value between 0 and 1 which is useful in making our prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# This model actually seems to work better with higher numbers\n",
    "model.add(Dense(400, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model.add(Dense(480, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #1\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "### 1 Layer\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | ---\n",
    "20 | 1 | 94.14%\n",
    "30 | 1 | 95.25%\n",
    "40 | 1 | 95.48%\n",
    "50 | 1 | 95.93%\n",
    "60 | 1 | 95.88%\n",
    "70 | 1 | 96.02%\n",
    "80 | 1 | 95.93%\n",
    "100 | 1 | 96.02%\n",
    "120 | 1 | 96.70%\n",
    "140 | 1 | 96.56%\n",
    "180 | 1 | 96.34%\n",
    "400 | 1 | 96.61%\n",
    "600 | 1 | 96.43%\n",
    "800 | 1 | 96.74%\n",
    "1000 | 1 | 96.65%\n",
    "1200 | 1 | 96.16%\n",
    "1600 | 1 | 96.34%\n",
    "2000 | 1 | 96.07%\n",
    "2200 | 1 | 96.65%\n",
    "**2300** | **1** | **97.11%**\n",
    "2400 | 1 | 96.83%\n",
    "3200 | 1 | 96.20%\n",
    "4600 | 1 | 96.56%\n",
    "6900 | 1 | 96.79%\n",
    "9200 | 1 | 96.74%\n",
    "11500 | 1 | 96.52%\n",
    "\n",
    "We took the best 2300 neurons result and ran it again 10 time.\n",
    "\n",
    "*96.47%, 97.01%, 96.34%, 96.56%, 96.70%, 96.43%, 96.88%, 96.38%, 96.83%, 96.92%*\n",
    "\n",
    "average = 96.652%\n",
    "\n",
    "We also took the second best result 2400 neurons and rain it again 5 times.\n",
    "\n",
    "*96.61%, 96.47%, 96.92, 96.61, 96.34%*\n",
    "\n",
    "average = 96.59%\n",
    "\n",
    "\n",
    "*While 2300 yielded the highest result, we attempted to run the model with 2300 again 5 seperate times and each time the result was under 97%.*\n",
    "\n",
    "### 2 Layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "30 | 40 | 1 | 95.52%\n",
    "40 | 30 | 1 | 91.30%\n",
    "30 | 50 | 1 | 91.30%\n",
    "40 | 50 | 1 | 95.66%\n",
    "50 | 60 | 1 | 96.20%\n",
    "60 | 70 | 1 | 91.30%\n",
    "100 | 120 | 1 | 96.25%\n",
    "200 | 240 | 1 | 96.47%\n",
    "**400** | **480** | **1** | **96.88%**\n",
    "800 | 960 | 1 | 96.70%\n",
    "1200 | 1300 | 1 | 91.30%\n",
    "1600 | 1920 | 1 | 96.79%\n",
    "3200 | 3840 | 1 | 96.83%\n",
    "6400 | 7680 | 1 | 96.61%\n",
    "6900 | 7680 | 1 | 96.38%\n",
    "12800 | 15360 | 1 | 96.11%\n",
    "\n",
    "We took the best result and ran it again 5 times. \n",
    "\n",
    "*96.70%, 96.97%, 97.29%, 96.83%, 96.61%, 96.16%, 96.92%, 96.25%, 96.34%, 96.83%*\n",
    "\n",
    "average = 96.69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 30)                930       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 40)                1240      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 41        \n",
      "=================================================================\n",
      "Total params: 2,211\n",
      "Trainable params: 2,211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #2\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "135 | 111 | 1 | 92.55%\n",
    "145 | 111 | 1 | 92.30%\n",
    "270 | 222 | 1 | 93.73%\n",
    "540 | 444 | 1 | 91.84%\n",
    "600 | 450 | 1 | 92.79%\n",
    "600 | 500 | 1 | 92.24%\n",
    "135 | 135 | 1 | 93.16%\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "111 | 135 | 1 | 92.70%\n",
    "222 | 270 | 1 | 93.18%\n",
    "450 | 600 | 1 | 93.53%\n",
    "666 | 777 | 1 | 91.89%\n",
    "900 | 1200 | 1 | 93.13%\n",
    "\n",
    "Trying with 2 instead of 3 layers.\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | --- \n",
    "111 | 1 | 92.30%\n",
    "135 | 1 | 93.05%\n",
    "270 | 1 | 92.38%\n",
    "540 | 1 | 93.07%\n",
    "1080 | 1 | 92.42%\n",
    "\n",
    "\n",
    "Trying with 4 instead of 3 layers.\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | Accuracy\n",
    "--- | --- | --- | --- | ---\n",
    "111 | 111 | 111 | 1 | 93.46%\n",
    "**135** | **135** | **135** | **1** | **93.92%**\n",
    "270 | 222 | 135 | 1 | 93.38%\n",
    "166 | 166 | 166 | 1 | 93.72%\n",
    "270 | 270 | 270 | 1 | 93.65%\n",
    "600 | 270 | 135 | 1 | 92.60%\n",
    "888 | 888 | 888 | 1 | 93.31%\n",
    "160 | 150 | 140 | 1 | 93.59%\n",
    "140 | 140 | 140 | 1 | 93.79%\n",
    "130 | 130 | 130 | 1 | 92.99%\n",
    "135 | 270 | 600 | 1 | 93.55%\n",
    "\n",
    "\n",
    "Trying with 5 layers\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | ---\n",
    "135 | 135 | 135 | 135 | 1 | 92.26%\n",
    "140 | 140 | 140 | 140 | 1 | 93.95%\n",
    "145 | 145 | 145 | 145 | 1 | 93.63%\n",
    "166 | 166 | 166 | 166 | 1 | 93.67%\n",
    "270 | 270 | 270 | 270 | 1 | 93.81%\n",
    "280 | 280 | 280 | 280 | 1 | 93.78%\n",
    "135 | 270 | 500 | 1000 | 1 | 94.02%\n",
    "135 | 270 | 540 | 1080 | 1 | 92.45%\n",
    "140 | 280 | 540 | 1080 | 1 | 93.50%\n",
    "270 | 560 | 1080 | 2160 | 1 | 93.07%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building using the Sequential API\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(135, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x2.shape[1]))\n",
    "model2.add(Dense(270, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(540, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1080, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 270)               30240     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 270)               73170     \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 270)               73170     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 271       \n",
      "=================================================================\n",
      "Total params: 176,851\n",
      "Trainable params: 176,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "es_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 0s 30us/step - loss: 0.1256 - accuracy: 0.9493\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 0s 31us/step - loss: 0.1253 - accuracy: 0.9504\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 0s 30us/step - loss: 0.1247 - accuracy: 0.9498\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 0s 34us/step - loss: 0.1252 - accuracy: 0.9487\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 0s 34us/step - loss: 0.1243 - accuracy: 0.9490\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 0s 31us/step - loss: 0.1240 - accuracy: 0.9493\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 0s 32us/step - loss: 0.1233 - accuracy: 0.9506\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 0s 31us/step - loss: 0.1237 - accuracy: 0.9504\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 0s 32us/step - loss: 0.1226 - accuracy: 0.9512\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 0s 34us/step - loss: 0.1223 - accuracy: 0.9509\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 0s 36us/step - loss: 0.1222 - accuracy: 0.9512\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 0s 33us/step - loss: 0.1220 - accuracy: 0.9508\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 0s 32us/step - loss: 0.1214 - accuracy: 0.9514\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 0s 32us/step - loss: 0.1208 - accuracy: 0.9508\n",
      "Epoch 15/128\n",
      "4480/8844 [==============>...............] - ETA: 0s - loss: 0.1242 - accuracy: 0.9507"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-175-cb7a76e1b055>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mes_cb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nAccuracy score of the Neural Network {0:.2f}%'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    199\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/callbacks/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         if (self._delta_t_batch > 0. and\n\u001b[1;32m     90\u001b[0m            \u001b[0mdelta_t_median\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.95\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_t_batch\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mmedian\u001b[0;34m(a, axis, out, overwrite_input, keepdims)\u001b[0m\n\u001b[1;32m   3493\u001b[0m     \"\"\"\n\u001b[1;32m   3494\u001b[0m     r, k = _ureduce(a, func=_median, axis=axis, out=out,\n\u001b[0;32m-> 3495\u001b[0;31m                     overwrite_input=overwrite_input)\n\u001b[0m\u001b[1;32m   3496\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_ureduce\u001b[0;34m(a, func, **kwargs)\u001b[0m\n\u001b[1;32m   3401\u001b[0m         \u001b[0mkeepdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3403\u001b[0;31m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3404\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_median\u001b[0;34m(a, axis, out, overwrite_input)\u001b[0m\n\u001b[1;32m   3547\u001b[0m         \u001b[0;31m# warn and return nans like mean would\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3548\u001b[0m         \u001b[0mrout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3549\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_median_nancheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3550\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3551\u001b[0m         \u001b[0;31m# if there are no nans\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/lib/utils.py\u001b[0m in \u001b[0;36m_median_nancheck\u001b[0;34m(data, result, axis, out)\u001b[0m\n\u001b[1;32m   1070\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1071\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1072\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveaxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1073\u001b[0m     \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1074\u001b[0m     \u001b[0;31m# masked NaN values are ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1403\u001b[0m     \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mn\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1405\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestination\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1406\u001b[0m         \u001b[0morder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "70917/70917 [==============================] - 27s 379us/step - loss: 0.7101 - accuracy: 0.7686\n",
      "Epoch 2/128\n",
      "70917/70917 [==============================] - 26s 371us/step - loss: 0.2798 - accuracy: 0.8875\n",
      "Epoch 3/128\n",
      "70917/70917 [==============================] - 27s 380us/step - loss: 0.2320 - accuracy: 0.9034\n",
      "Epoch 4/128\n",
      "70917/70917 [==============================] - 27s 387us/step - loss: 0.2227 - accuracy: 0.9065\n",
      "Epoch 5/128\n",
      "70917/70917 [==============================] - 29s 413us/step - loss: 0.2207 - accuracy: 0.9065\n",
      "Epoch 6/128\n",
      "70917/70917 [==============================] - 38s 533us/step - loss: 0.2095 - accuracy: 0.9132\n",
      "Epoch 7/128\n",
      "70917/70917 [==============================] - 62s 874us/step - loss: 0.2034 - accuracy: 0.9154\n",
      "Epoch 8/128\n",
      "70917/70917 [==============================] - 62s 878us/step - loss: 0.1996 - accuracy: 0.9176\n",
      "Epoch 9/128\n",
      "70917/70917 [==============================] - 71s 997us/step - loss: 0.1982 - accuracy: 0.9174\n",
      "Epoch 10/128\n",
      "70917/70917 [==============================] - 63s 891us/step - loss: 0.1928 - accuracy: 0.9205\n",
      "Epoch 11/128\n",
      "70917/70917 [==============================] - 39s 550us/step - loss: 0.1899 - accuracy: 0.9226\n",
      "Epoch 12/128\n",
      "70917/70917 [==============================] - 42s 595us/step - loss: 0.1903 - accuracy: 0.9213\n",
      "Epoch 13/128\n",
      "70917/70917 [==============================] - 28s 393us/step - loss: 0.1883 - accuracy: 0.9226\n",
      "Epoch 14/128\n",
      "70917/70917 [==============================] - 27s 374us/step - loss: 0.1832 - accuracy: 0.9239\n",
      "Epoch 15/128\n",
      "70917/70917 [==============================] - 27s 388us/step - loss: 0.1875 - accuracy: 0.9237\n",
      "Epoch 16/128\n",
      "70917/70917 [==============================] - 26s 360us/step - loss: 0.1836 - accuracy: 0.9249\n",
      "Epoch 17/128\n",
      "70917/70917 [==============================] - 25s 357us/step - loss: 0.1773 - accuracy: 0.9266\n",
      "Epoch 18/128\n",
      "70917/70917 [==============================] - 26s 360us/step - loss: 0.1806 - accuracy: 0.9249\n",
      "Epoch 19/128\n",
      "70917/70917 [==============================] - 25s 358us/step - loss: 0.1773 - accuracy: 0.9268\n",
      "Epoch 20/128\n",
      "70917/70917 [==============================] - 28s 394us/step - loss: 0.1806 - accuracy: 0.9273\n",
      "Epoch 21/128\n",
      "70917/70917 [==============================] - 26s 370us/step - loss: 0.1781 - accuracy: 0.9267\n",
      "Epoch 22/128\n",
      "70917/70917 [==============================] - 28s 400us/step - loss: 0.1770 - accuracy: 0.9280\n",
      "17730/17730 [==============================] - 2s 118us/step\n",
      "\n",
      "Accuracy score of the Neural Network 92.45%\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train2, y_train2, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores2 = model2.evaluate(x_test2, y_test2)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TDLHBA hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(400, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model_TDLHBA.add(Dense(480, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.0017470)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8844/8844 [==============================] - 4s 484us/step - loss: 0.1924 - accuracy: 0.9254\n",
      "Epoch 2/100\n",
      "8844/8844 [==============================] - 4s 451us/step - loss: 0.1463 - accuracy: 0.9403\n",
      "Epoch 3/100\n",
      "8844/8844 [==============================] - 4s 458us/step - loss: 0.1289 - accuracy: 0.9452\n",
      "Epoch 4/100\n",
      "8844/8844 [==============================] - 4s 457us/step - loss: 0.1151 - accuracy: 0.9505\n",
      "Epoch 5/100\n",
      "8844/8844 [==============================] - 4s 452us/step - loss: 0.1108 - accuracy: 0.9549\n",
      "Epoch 6/100\n",
      "8844/8844 [==============================] - 4s 454us/step - loss: 0.0959 - accuracy: 0.9590\n",
      "Epoch 7/100\n",
      "8844/8844 [==============================] - 4s 467us/step - loss: 0.0854 - accuracy: 0.9623\n",
      "Epoch 8/100\n",
      "8844/8844 [==============================] - 5s 514us/step - loss: 0.0804 - accuracy: 0.9642\n",
      "Epoch 9/100\n",
      "8844/8844 [==============================] - 5s 526us/step - loss: 0.0817 - accuracy: 0.9655\n",
      "Epoch 10/100\n",
      "8844/8844 [==============================] - 4s 504us/step - loss: 0.0716 - accuracy: 0.9680\n",
      "Epoch 11/100\n",
      "8844/8844 [==============================] - 4s 492us/step - loss: 0.0699 - accuracy: 0.9703\n",
      "Epoch 12/100\n",
      "8844/8844 [==============================] - 4s 508us/step - loss: 0.0680 - accuracy: 0.9720\n",
      "Epoch 13/100\n",
      "8844/8844 [==============================] - 5s 525us/step - loss: 0.0613 - accuracy: 0.9741\n",
      "Epoch 14/100\n",
      "8844/8844 [==============================] - 4s 495us/step - loss: 0.0699 - accuracy: 0.9701\n",
      "Epoch 15/100\n",
      "8844/8844 [==============================] - 4s 478us/step - loss: 0.0577 - accuracy: 0.9754\n",
      "Epoch 16/100\n",
      "8844/8844 [==============================] - 4s 482us/step - loss: 0.0551 - accuracy: 0.9755\n",
      "Epoch 17/100\n",
      "8844/8844 [==============================] - 5s 520us/step - loss: 0.0560 - accuracy: 0.9768\n",
      "Epoch 18/100\n",
      "8844/8844 [==============================] - 4s 500us/step - loss: 0.0639 - accuracy: 0.9761\n",
      "Epoch 19/100\n",
      "8844/8844 [==============================] - 4s 498us/step - loss: 0.0551 - accuracy: 0.9790\n",
      "Epoch 20/100\n",
      "8844/8844 [==============================] - 4s 472us/step - loss: 0.0500 - accuracy: 0.9794\n",
      "Epoch 21/100\n",
      "8844/8844 [==============================] - 4s 463us/step - loss: 0.0465 - accuracy: 0.9800\n",
      "Epoch 22/100\n",
      "8844/8844 [==============================] - 4s 464us/step - loss: 0.0490 - accuracy: 0.9795\n",
      "Epoch 23/100\n",
      "8844/8844 [==============================] - 4s 468us/step - loss: 0.0443 - accuracy: 0.9804\n",
      "Epoch 24/100\n",
      "8844/8844 [==============================] - 5s 534us/step - loss: 0.0450 - accuracy: 0.9799\n",
      "Epoch 25/100\n",
      "8844/8844 [==============================] - 4s 495us/step - loss: 0.0472 - accuracy: 0.9801\n",
      "Epoch 26/100\n",
      "8844/8844 [==============================] - 5s 520us/step - loss: 0.0404 - accuracy: 0.9820\n",
      "Epoch 27/100\n",
      "8844/8844 [==============================] - 4s 508us/step - loss: 0.0438 - accuracy: 0.9813\n",
      "Epoch 28/100\n",
      "8844/8844 [==============================] - 4s 416us/step - loss: 0.0503 - accuracy: 0.9822\n",
      "Epoch 29/100\n",
      "8844/8844 [==============================] - 4s 440us/step - loss: 0.0386 - accuracy: 0.9837\n",
      "Epoch 30/100\n",
      "8844/8844 [==============================] - 4s 438us/step - loss: 0.0431 - accuracy: 0.9825\n",
      "Epoch 31/100\n",
      "8844/8844 [==============================] - 4s 500us/step - loss: 0.0361 - accuracy: 0.9830\n",
      "Epoch 32/100\n",
      "8844/8844 [==============================] - 4s 507us/step - loss: 0.0404 - accuracy: 0.9829\n",
      "Epoch 33/100\n",
      "8844/8844 [==============================] - 4s 503us/step - loss: 0.0349 - accuracy: 0.9843\n",
      "Epoch 34/100\n",
      "8844/8844 [==============================] - 4s 475us/step - loss: 0.0344 - accuracy: 0.9859\n",
      "Epoch 35/100\n",
      "8844/8844 [==============================] - 4s 444us/step - loss: 0.0342 - accuracy: 0.9853\n",
      "Epoch 36/100\n",
      "8844/8844 [==============================] - 6s 651us/step - loss: 0.0379 - accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "8844/8844 [==============================] - 6s 682us/step - loss: 0.0359 - accuracy: 0.9851\n",
      "Epoch 38/100\n",
      "8844/8844 [==============================] - 4s 456us/step - loss: 0.0307 - accuracy: 0.9855\n",
      "Epoch 39/100\n",
      "8844/8844 [==============================] - 4s 414us/step - loss: 0.0323 - accuracy: 0.9850\n",
      "Epoch 40/100\n",
      "8844/8844 [==============================] - 4s 423us/step - loss: 0.0750 - accuracy: 0.9799\n",
      "Epoch 41/100\n",
      "8844/8844 [==============================] - 4s 456us/step - loss: 0.0305 - accuracy: 0.9858\n",
      "Epoch 42/100\n",
      "8844/8844 [==============================] - 4s 447us/step - loss: 0.0302 - accuracy: 0.9860\n",
      "Epoch 43/100\n",
      "8844/8844 [==============================] - 4s 409us/step - loss: 0.0287 - accuracy: 0.9871\n",
      "Epoch 44/100\n",
      "8844/8844 [==============================] - 4s 426us/step - loss: 0.0285 - accuracy: 0.9867\n",
      "Epoch 45/100\n",
      "8844/8844 [==============================] - 4s 444us/step - loss: 0.0308 - accuracy: 0.9851\n",
      "Epoch 46/100\n",
      "8844/8844 [==============================] - 4s 410us/step - loss: 0.0281 - accuracy: 0.9868\n",
      "Epoch 47/100\n",
      "8844/8844 [==============================] - 4s 409us/step - loss: 0.0372 - accuracy: 0.9855\n",
      "Epoch 48/100\n",
      "8844/8844 [==============================] - 4s 413us/step - loss: 0.0324 - accuracy: 0.9861\n",
      "2211/2211 [==============================] - 0s 63us/step\n",
      "\n",
      "Accuracy score of the Neural Network with TDLHBA hyperparameter settings 96.83%\n"
     ]
    }
   ],
   "source": [
    "history_TDLHBA = model_TDLHBA.fit(x_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model_TDLHBA.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with TDLHBA hyperparameter settings {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
