{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #1\n",
    "\n",
    "Get the first dataset with 30 attributes plus result from R. M. Mohammad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
       "0                 -1           1                   1                 1   \n",
       "1                  1           1                   1                 1   \n",
       "2                  1           0                   1                 1   \n",
       "3                  1           0                   1                 1   \n",
       "4                  1           0                  -1                 1   \n",
       "5                 -1           0                  -1                 1   \n",
       "6                  1           0                  -1                 1   \n",
       "7                  1           0                   1                 1   \n",
       "8                  1           0                  -1                 1   \n",
       "9                  1           1                  -1                 1   \n",
       "\n",
       "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
       "0                        -1             -1                 -1              -1   \n",
       "1                         1             -1                  0               1   \n",
       "2                         1             -1                 -1              -1   \n",
       "3                         1             -1                 -1              -1   \n",
       "4                         1             -1                  1               1   \n",
       "5                        -1             -1                  1               1   \n",
       "6                         1             -1                 -1              -1   \n",
       "7                         1             -1                 -1              -1   \n",
       "8                         1             -1                  1               1   \n",
       "9                         1             -1                 -1               1   \n",
       "\n",
       "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
       "0                           -1        1  ...            1       1   \n",
       "1                           -1        1  ...            1       1   \n",
       "2                           -1        1  ...            1       1   \n",
       "3                            1        1  ...            1       1   \n",
       "4                           -1        1  ...           -1       1   \n",
       "5                           -1        1  ...            1       1   \n",
       "6                            1        1  ...            1       1   \n",
       "7                            1        1  ...            1       1   \n",
       "8                           -1        1  ...            1       1   \n",
       "9                           -1        1  ...            1       1   \n",
       "\n",
       "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
       "0             -1         -1           -1         -1             1   \n",
       "1             -1         -1            0         -1             1   \n",
       "2              1         -1            1         -1             1   \n",
       "3             -1         -1            1         -1             1   \n",
       "4             -1         -1            0         -1             1   \n",
       "5              1          1            1         -1             1   \n",
       "6              1         -1           -1         -1             1   \n",
       "7             -1         -1            0         -1             1   \n",
       "8              1         -1            1          1             1   \n",
       "9              1         -1            0         -1             1   \n",
       "\n",
       "   Links_pointing_to_page  Statistical_report  Result  \n",
       "0                       1                  -1      -1  \n",
       "1                       1                   1      -1  \n",
       "2                       0                  -1      -1  \n",
       "3                      -1                   1      -1  \n",
       "4                       1                   1       1  \n",
       "5                      -1                  -1       1  \n",
       "6                       0                  -1      -1  \n",
       "7                       0                   1      -1  \n",
       "8                       0                   1       1  \n",
       "9                       0                   1      -1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url=\"./dataset1.csv\"\n",
    "df=pd.read_csv(url)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #1. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #1 : 11055\n",
      "Column count for dataset #1 : 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #1 :\", str(df.shape[0]))\n",
    "print(\"Column count for dataset #1 :\", str(df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #2\n",
    "\n",
    "Get the second dataset with 111 attributes plus result from Vrbančič."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0            3               0                  0              1   \n",
       "1            5               0                  1              3   \n",
       "2            2               0                  0              1   \n",
       "3            4               0                  2              5   \n",
       "4            2               0                  0              0   \n",
       "5            1               0                  0              2   \n",
       "6            2               0                  0              0   \n",
       "7            2               0                  0              3   \n",
       "8            2               0                  0              0   \n",
       "9            1               0                  0              2   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              3           0            2   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "5                     0              0           0            0   \n",
       "6                     0              0           0            0   \n",
       "7                     0              0           0            0   \n",
       "8                     0              0           0            0   \n",
       "9                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  qty_nameservers  \\\n",
       "0                    0              0  ...                1                2   \n",
       "1                    0              0  ...                1                2   \n",
       "2                    0              0  ...                1                2   \n",
       "3                    0              0  ...                1                2   \n",
       "4                    0              0  ...                1                2   \n",
       "5                    0              0  ...                1                3   \n",
       "6                    0              0  ...                1                2   \n",
       "7                    0              0  ...                1                2   \n",
       "8                    0              0  ...                1                4   \n",
       "9                    0              0  ...                1                2   \n",
       "\n",
       "   qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0               0           892                    0              0   \n",
       "1               1          9540                    1              0   \n",
       "2               3           589                    1              0   \n",
       "3               0           292                    1              0   \n",
       "4               1          3597                    0              1   \n",
       "5               3          3591                    1              0   \n",
       "6               2           291                    0              0   \n",
       "7               1          3134                    1              0   \n",
       "8               2          3596                    1              1   \n",
       "9               1         14397                    1              0   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  \n",
       "5                 0                    0              0         1  \n",
       "6                 0                    0              0         0  \n",
       "7                 0                    0              0         0  \n",
       "8                 0                    0              0         0  \n",
       "9                 0                    0              0         1  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2=\"./dataset2.csv\"\n",
    "df2=pd.read_csv(url2)\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #2. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #2 : 88647\n",
      "Column count for dataset #2 : 111\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #2 :\", str(df2.shape[0]))\n",
    "print(\"Column count for dataset #2 :\", str(df2.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #3\n",
    "\n",
    "The original paper Dataset #3 is inspired from describes using the following:\n",
    "\n",
    "    To train both models, a dataset of real and phishing URLs was constructed. In total, 2 million URLs were used in the training process. Half of them legitimate and half of them phishing. The legitimate URLs came from Common Crawl, a corpus of web crawl data. The phishing URLs came from Phishtank...\n",
    "    \n",
    "\n",
    "\n",
    "Using this dataset in place which is significantly smaller [this kaggle dataset](https://www.kaggle.com/kunal4892/phishingandlegitimateurls). We have 96,000 rows total as compared to the original experiment which contained 2 million rows. *Working on getting the original dataset to improve our results here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.voting-yahoo.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.zvon.org/xxl/WSDL1.1/Output/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tecportais.com/file-security-update-infonfmati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bima.astro.umd.edu/nemo/linuxastro/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>huarui-tec.com/js/?us.battle.net/login/en/?ref...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diannaopeizhi.com/js/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.synchrotech.com/support/install.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.ansi.okstate.edu/breeds/swine/largeblackwh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.strum.co.uk/webbery/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.grok2.com/vi-emacs.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              domain  label\n",
       "0                               www.voting-yahoo.com      1\n",
       "1         www.zvon.org/xxl/WSDL1.1/Output/index.html      0\n",
       "2  tecportais.com/file-security-update-infonfmati...      1\n",
       "3                bima.astro.umd.edu/nemo/linuxastro/      0\n",
       "4  huarui-tec.com/js/?us.battle.net/login/en/?ref...      1\n",
       "5                              diannaopeizhi.com/js/      1\n",
       "6           www.synchrotech.com/support/install.html      0\n",
       "7  www.ansi.okstate.edu/breeds/swine/largeblackwh...      0\n",
       "8                           www.strum.co.uk/webbery/      0\n",
       "9                        www.grok2.com/vi-emacs.html      0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3=\"./dataset3.csv\"\n",
    "df3=pd.read_csv(url3)\n",
    "\n",
    "# Remove all columns except URL and label\n",
    "df3 = df3.drop(df3.columns[[1,2,3,4,5,6,7,8,9,10]], axis=1)\n",
    "\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #3 : 95910\n",
      "Column count for dataset #3 : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #3 :\", str(df3.shape[0]))\n",
    "print(\"Column count for dataset #3 :\", str(df3.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "On the first dataset convert value of -1 to 0 for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Result'].values[df['Result'].values < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will replace any missing values with the mean value for that column. This will be done for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use mean value for any nan values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df2.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split both of our datasets into section for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the Data\n",
    "\n",
    "Next we need to seperate each dataset into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data up into training and test data\n",
    "x = df.iloc[:,0:30].values.astype(int)\n",
    "y = df.iloc[:,30].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x2 = df2.iloc[:,0:111].values.astype(int)\n",
    "y2 = df2.iloc[:,111].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x3 = df3.iloc[:,0:1].values.astype(str)\n",
    "y3 = df3.iloc[:,1].values.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Baseline Result\n",
    "\n",
    "Import `numpy` and set a random seed so that random values will be the same each time we run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a baseline comparision for our neural network we'll do a round of logitstic regression with a maximum iteration of 10,000. We'll use our training and test set from each dataset to get an accuracy score for both datasets while using logistic regression.\n",
    "\n",
    "This will be the baseline value to beat when using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'precision_recall_fscore_support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-5704fb17b028>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0my_pred2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogisticRegr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogisticRegr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0mt2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogisticRegr2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'precision_recall_fscore_support' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_pred=logisticRegr.predict(x_test)\n",
    "\n",
    "logisticRegr2 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr2.fit(x_train2, y_train2)\n",
    "y_pred2=logisticRegr2.predict(x_test2)\n",
    "\n",
    "t = precision_recall_fscore_support(y_test, logisticRegr.predict(x_test), average='micro')\n",
    "t2 = precision_recall_fscore_support(y_test2, logisticRegr2.predict(x_test2), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9240162822252375\n",
      "Precision: 0.9276160503540519\n",
      "Recall: 0.9394422310756972\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9217146080090243\n",
      "Precision: 0.8633988936693301\n",
      "Recall: 0.9184373978424322\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision:\",metrics.precision_score(y_test2, y_pred2))\n",
    "print(\"Recall:\",metrics.recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #3\n",
    "\n",
    "As we've removed all attributes from our URLs for dataset #3 and are only left with a string for each row logistic regression will not be particularly useful as it requires first converting the string to a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Next we'll move to using our same datasets with a neural network. We're using 2 different rectified linear unit layers each with a slightly different amount of neurons. The results from these 2 layers arrives sequentially at the last layer sigmoid which produces a prediction. The sigmoid layer always produces a value between 0 and 1 which is useful in making our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# This model actually seems to work better with higher numbers\n",
    "model.add(Dense(400, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model.add(Dense(480, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #1\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "### 1 Layer\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | ---\n",
    "20 | 1 | 94.14%\n",
    "30 | 1 | 95.25%\n",
    "40 | 1 | 95.48%\n",
    "50 | 1 | 95.93%\n",
    "60 | 1 | 95.88%\n",
    "70 | 1 | 96.02%\n",
    "80 | 1 | 95.93%\n",
    "100 | 1 | 96.02%\n",
    "120 | 1 | 96.70%\n",
    "140 | 1 | 96.56%\n",
    "180 | 1 | 96.34%\n",
    "400 | 1 | 96.61%\n",
    "600 | 1 | 96.43%\n",
    "800 | 1 | 96.74%\n",
    "1000 | 1 | 96.65%\n",
    "1200 | 1 | 96.16%\n",
    "1600 | 1 | 96.34%\n",
    "2000 | 1 | 96.07%\n",
    "2200 | 1 | 96.65%\n",
    "**2300** | **1** | **97.11%**\n",
    "2400 | 1 | 96.83%\n",
    "3200 | 1 | 96.20%\n",
    "4600 | 1 | 96.56%\n",
    "6900 | 1 | 96.79%\n",
    "9200 | 1 | 96.74%\n",
    "11500 | 1 | 96.52%\n",
    "\n",
    "We took the best 2300 neurons result and ran it again 10 time.\n",
    "\n",
    "*96.47%, 97.01%, 96.34%, 96.56%, 96.70%, 96.43%, 96.88%, 96.38%, 96.83%, 96.92%*\n",
    "\n",
    "average = 96.652%\n",
    "\n",
    "We also took the second best result 2400 neurons and rain it again 5 times.\n",
    "\n",
    "*96.61%, 96.47%, 96.92, 96.61, 96.34%*\n",
    "\n",
    "average = 96.59%\n",
    "\n",
    "\n",
    "*While 2300 yielded the highest result, we attempted to run the model with 2300 again 5 seperate times and each time the result was under 97%.*\n",
    "\n",
    "### 2 Layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "30 | 40 | 1 | 95.52%\n",
    "40 | 30 | 1 | 91.30%\n",
    "30 | 50 | 1 | 91.30%\n",
    "40 | 50 | 1 | 95.66%\n",
    "50 | 60 | 1 | 96.20%\n",
    "60 | 70 | 1 | 91.30%\n",
    "100 | 120 | 1 | 96.25%\n",
    "200 | 240 | 1 | 96.47%\n",
    "**400** | **480** | **1** | **96.88%**\n",
    "800 | 960 | 1 | 96.70%\n",
    "1200 | 1300 | 1 | 91.30%\n",
    "1600 | 1920 | 1 | 96.79%\n",
    "3200 | 3840 | 1 | 96.83%\n",
    "6400 | 7680 | 1 | 96.61%\n",
    "6900 | 7680 | 1 | 96.38%\n",
    "12800 | 15360 | 1 | 96.11%\n",
    "\n",
    "We took the best result and ran it again 5 times. \n",
    "\n",
    "*96.70%, 96.97%, 97.29%, 96.83%, 96.61%, 96.16%, 96.92%, 96.25%, 96.34%, 96.83%*\n",
    "\n",
    "average = 96.69%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 400)               12400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 480)               192480    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 481       \n",
      "=================================================================\n",
      "Total params: 205,361\n",
      "Trainable params: 205,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "es_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #2\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "135 | 111 | 1 | 92.55%\n",
    "145 | 111 | 1 | 92.30%\n",
    "270 | 222 | 1 | 93.73%\n",
    "540 | 444 | 1 | 91.84%\n",
    "600 | 450 | 1 | 92.79%\n",
    "600 | 500 | 1 | 92.24%\n",
    "135 | 135 | 1 | 93.16%\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "111 | 135 | 1 | 92.70%\n",
    "222 | 270 | 1 | 93.18%\n",
    "450 | 600 | 1 | 93.53%\n",
    "666 | 777 | 1 | 91.89%\n",
    "900 | 1200 | 1 | 93.13%\n",
    "\n",
    "Trying with 2 instead of 3 layers.\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | --- \n",
    "111 | 1 | 92.30%\n",
    "135 | 1 | 93.05%\n",
    "270 | 1 | 92.38%\n",
    "540 | 1 | 93.07%\n",
    "1080 | 1 | 92.42%\n",
    "\n",
    "\n",
    "Trying with 4 instead of 3 layers.\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | Accuracy\n",
    "--- | --- | --- | --- | ---\n",
    "111 | 111 | 111 | 1 | 93.46%\n",
    "**135** | **135** | **135** | **1** | **93.92%**\n",
    "270 | 222 | 135 | 1 | 93.38%\n",
    "166 | 166 | 166 | 1 | 93.72%\n",
    "270 | 270 | 270 | 1 | 93.65%\n",
    "600 | 270 | 135 | 1 | 92.60%\n",
    "888 | 888 | 888 | 1 | 93.31%\n",
    "160 | 150 | 140 | 1 | 93.59%\n",
    "140 | 140 | 140 | 1 | 93.79%\n",
    "130 | 130 | 130 | 1 | 92.99%\n",
    "135 | 270 | 600 | 1 | 93.55%\n",
    "\n",
    "\n",
    "Trying with 5 layers\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | ---\n",
    "135 | 135 | 135 | 135 | 1 | 92.26%\n",
    "140 | 140 | 140 | 140 | 1 | 93.95%\n",
    "145 | 145 | 145 | 145 | 1 | 93.63%\n",
    "166 | 166 | 166 | 166 | 1 | 93.67%\n",
    "270 | 270 | 270 | 270 | 1 | 93.81%\n",
    "280 | 280 | 280 | 280 | 1 | 93.78%\n",
    "135 | 270 | 500 | 1000 | 1 | 94.02%\n",
    "135 | 270 | 540 | 1080 | 1 | 92.45%\n",
    "140 | 280 | 540 | 1080 | 1 | 93.50%\n",
    "270 | 560 | 1080 | 2160 | 1 | 93.07%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building using the Sequential API\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(135, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x2.shape[1]))\n",
    "model2.add(Dense(270, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(540, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1080, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_56\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_131 (Dense)            (None, 270)               30240     \n",
      "_________________________________________________________________\n",
      "dense_132 (Dense)            (None, 270)               73170     \n",
      "_________________________________________________________________\n",
      "dense_133 (Dense)            (None, 270)               73170     \n",
      "_________________________________________________________________\n",
      "dense_134 (Dense)            (None, 1)                 271       \n",
      "=================================================================\n",
      "Total params: 176,851\n",
      "Trainable params: 176,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "70917/70917 [==============================] - 27s 379us/step - loss: 0.7101 - accuracy: 0.7686\n",
      "Epoch 2/128\n",
      "70917/70917 [==============================] - 26s 371us/step - loss: 0.2798 - accuracy: 0.8875\n",
      "Epoch 3/128\n",
      "70917/70917 [==============================] - 27s 380us/step - loss: 0.2320 - accuracy: 0.9034\n",
      "Epoch 4/128\n",
      "70917/70917 [==============================] - 27s 387us/step - loss: 0.2227 - accuracy: 0.9065\n",
      "Epoch 5/128\n",
      "70917/70917 [==============================] - 29s 413us/step - loss: 0.2207 - accuracy: 0.9065\n",
      "Epoch 6/128\n",
      "70917/70917 [==============================] - 38s 533us/step - loss: 0.2095 - accuracy: 0.9132\n",
      "Epoch 7/128\n",
      "70917/70917 [==============================] - 62s 874us/step - loss: 0.2034 - accuracy: 0.9154\n",
      "Epoch 8/128\n",
      "70917/70917 [==============================] - 62s 878us/step - loss: 0.1996 - accuracy: 0.9176\n",
      "Epoch 9/128\n",
      "70917/70917 [==============================] - 71s 997us/step - loss: 0.1982 - accuracy: 0.9174\n",
      "Epoch 10/128\n",
      "70917/70917 [==============================] - 63s 891us/step - loss: 0.1928 - accuracy: 0.9205\n",
      "Epoch 11/128\n",
      "70917/70917 [==============================] - 39s 550us/step - loss: 0.1899 - accuracy: 0.9226\n",
      "Epoch 12/128\n",
      "70917/70917 [==============================] - 42s 595us/step - loss: 0.1903 - accuracy: 0.9213\n",
      "Epoch 13/128\n",
      "70917/70917 [==============================] - 28s 393us/step - loss: 0.1883 - accuracy: 0.9226\n",
      "Epoch 14/128\n",
      "70917/70917 [==============================] - 27s 374us/step - loss: 0.1832 - accuracy: 0.9239\n",
      "Epoch 15/128\n",
      "70917/70917 [==============================] - 27s 388us/step - loss: 0.1875 - accuracy: 0.9237\n",
      "Epoch 16/128\n",
      "70917/70917 [==============================] - 26s 360us/step - loss: 0.1836 - accuracy: 0.9249\n",
      "Epoch 17/128\n",
      "70917/70917 [==============================] - 25s 357us/step - loss: 0.1773 - accuracy: 0.9266\n",
      "Epoch 18/128\n",
      "70917/70917 [==============================] - 26s 360us/step - loss: 0.1806 - accuracy: 0.9249\n",
      "Epoch 19/128\n",
      "70917/70917 [==============================] - 25s 358us/step - loss: 0.1773 - accuracy: 0.9268\n",
      "Epoch 20/128\n",
      "70917/70917 [==============================] - 28s 394us/step - loss: 0.1806 - accuracy: 0.9273\n",
      "Epoch 21/128\n",
      "70917/70917 [==============================] - 26s 370us/step - loss: 0.1781 - accuracy: 0.9267\n",
      "Epoch 22/128\n",
      "70917/70917 [==============================] - 28s 400us/step - loss: 0.1770 - accuracy: 0.9280\n",
      "17730/17730 [==============================] - 2s 118us/step\n",
      "\n",
      "Accuracy score of the Neural Network 92.45%\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train2, y_train2, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores2 = model2.evaluate(x_test2, y_test2)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-90bfc48653fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Add a LSTM layer with 128 internal units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Add a Dense layer with 10 units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(10, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x3.shape[1]))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model3.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model3.add(layers.Dense(10))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TDLHBA hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(400, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model_TDLHBA.add(Dense(480, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.0017470)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_44\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_97 (Dense)             (None, 20)                620       \n",
      "_________________________________________________________________\n",
      "dense_98 (Dense)             (None, 1)                 21        \n",
      "=================================================================\n",
      "Total params: 641\n",
      "Trainable params: 641\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8844/8844 [==============================] - 4s 484us/step - loss: 0.1924 - accuracy: 0.9254\n",
      "Epoch 2/100\n",
      "8844/8844 [==============================] - 4s 451us/step - loss: 0.1463 - accuracy: 0.9403\n",
      "Epoch 3/100\n",
      "8844/8844 [==============================] - 4s 458us/step - loss: 0.1289 - accuracy: 0.9452\n",
      "Epoch 4/100\n",
      "8844/8844 [==============================] - 4s 457us/step - loss: 0.1151 - accuracy: 0.9505\n",
      "Epoch 5/100\n",
      "8844/8844 [==============================] - 4s 452us/step - loss: 0.1108 - accuracy: 0.9549\n",
      "Epoch 6/100\n",
      "8844/8844 [==============================] - 4s 454us/step - loss: 0.0959 - accuracy: 0.9590\n",
      "Epoch 7/100\n",
      "8844/8844 [==============================] - 4s 467us/step - loss: 0.0854 - accuracy: 0.9623\n",
      "Epoch 8/100\n",
      "8844/8844 [==============================] - 5s 514us/step - loss: 0.0804 - accuracy: 0.9642\n",
      "Epoch 9/100\n",
      "8844/8844 [==============================] - 5s 526us/step - loss: 0.0817 - accuracy: 0.9655\n",
      "Epoch 10/100\n",
      "8844/8844 [==============================] - 4s 504us/step - loss: 0.0716 - accuracy: 0.9680\n",
      "Epoch 11/100\n",
      "8844/8844 [==============================] - 4s 492us/step - loss: 0.0699 - accuracy: 0.9703\n",
      "Epoch 12/100\n",
      "8844/8844 [==============================] - 4s 508us/step - loss: 0.0680 - accuracy: 0.9720\n",
      "Epoch 13/100\n",
      "8844/8844 [==============================] - 5s 525us/step - loss: 0.0613 - accuracy: 0.9741\n",
      "Epoch 14/100\n",
      "8844/8844 [==============================] - 4s 495us/step - loss: 0.0699 - accuracy: 0.9701\n",
      "Epoch 15/100\n",
      "8844/8844 [==============================] - 4s 478us/step - loss: 0.0577 - accuracy: 0.9754\n",
      "Epoch 16/100\n",
      "8844/8844 [==============================] - 4s 482us/step - loss: 0.0551 - accuracy: 0.9755\n",
      "Epoch 17/100\n",
      "8844/8844 [==============================] - 5s 520us/step - loss: 0.0560 - accuracy: 0.9768\n",
      "Epoch 18/100\n",
      "8844/8844 [==============================] - 4s 500us/step - loss: 0.0639 - accuracy: 0.9761\n",
      "Epoch 19/100\n",
      "8844/8844 [==============================] - 4s 498us/step - loss: 0.0551 - accuracy: 0.9790\n",
      "Epoch 20/100\n",
      "8844/8844 [==============================] - 4s 472us/step - loss: 0.0500 - accuracy: 0.9794\n",
      "Epoch 21/100\n",
      "8844/8844 [==============================] - 4s 463us/step - loss: 0.0465 - accuracy: 0.9800\n",
      "Epoch 22/100\n",
      "8844/8844 [==============================] - 4s 464us/step - loss: 0.0490 - accuracy: 0.9795\n",
      "Epoch 23/100\n",
      "8844/8844 [==============================] - 4s 468us/step - loss: 0.0443 - accuracy: 0.9804\n",
      "Epoch 24/100\n",
      "8844/8844 [==============================] - 5s 534us/step - loss: 0.0450 - accuracy: 0.9799\n",
      "Epoch 25/100\n",
      "8844/8844 [==============================] - 4s 495us/step - loss: 0.0472 - accuracy: 0.9801\n",
      "Epoch 26/100\n",
      "8844/8844 [==============================] - 5s 520us/step - loss: 0.0404 - accuracy: 0.9820\n",
      "Epoch 27/100\n",
      "8844/8844 [==============================] - 4s 508us/step - loss: 0.0438 - accuracy: 0.9813\n",
      "Epoch 28/100\n",
      "8844/8844 [==============================] - 4s 416us/step - loss: 0.0503 - accuracy: 0.9822\n",
      "Epoch 29/100\n",
      "8844/8844 [==============================] - 4s 440us/step - loss: 0.0386 - accuracy: 0.9837\n",
      "Epoch 30/100\n",
      "8844/8844 [==============================] - 4s 438us/step - loss: 0.0431 - accuracy: 0.9825\n",
      "Epoch 31/100\n",
      "8844/8844 [==============================] - 4s 500us/step - loss: 0.0361 - accuracy: 0.9830\n",
      "Epoch 32/100\n",
      "8844/8844 [==============================] - 4s 507us/step - loss: 0.0404 - accuracy: 0.9829\n",
      "Epoch 33/100\n",
      "8844/8844 [==============================] - 4s 503us/step - loss: 0.0349 - accuracy: 0.9843\n",
      "Epoch 34/100\n",
      "8844/8844 [==============================] - 4s 475us/step - loss: 0.0344 - accuracy: 0.9859\n",
      "Epoch 35/100\n",
      "8844/8844 [==============================] - 4s 444us/step - loss: 0.0342 - accuracy: 0.9853\n",
      "Epoch 36/100\n",
      "8844/8844 [==============================] - 6s 651us/step - loss: 0.0379 - accuracy: 0.9848\n",
      "Epoch 37/100\n",
      "8844/8844 [==============================] - 6s 682us/step - loss: 0.0359 - accuracy: 0.9851\n",
      "Epoch 38/100\n",
      "8844/8844 [==============================] - 4s 456us/step - loss: 0.0307 - accuracy: 0.9855\n",
      "Epoch 39/100\n",
      "8844/8844 [==============================] - 4s 414us/step - loss: 0.0323 - accuracy: 0.9850\n",
      "Epoch 40/100\n",
      "8844/8844 [==============================] - 4s 423us/step - loss: 0.0750 - accuracy: 0.9799\n",
      "Epoch 41/100\n",
      "8844/8844 [==============================] - 4s 456us/step - loss: 0.0305 - accuracy: 0.9858\n",
      "Epoch 42/100\n",
      "8844/8844 [==============================] - 4s 447us/step - loss: 0.0302 - accuracy: 0.9860\n",
      "Epoch 43/100\n",
      "8844/8844 [==============================] - 4s 409us/step - loss: 0.0287 - accuracy: 0.9871\n",
      "Epoch 44/100\n",
      "8844/8844 [==============================] - 4s 426us/step - loss: 0.0285 - accuracy: 0.9867\n",
      "Epoch 45/100\n",
      "8844/8844 [==============================] - 4s 444us/step - loss: 0.0308 - accuracy: 0.9851\n",
      "Epoch 46/100\n",
      "8844/8844 [==============================] - 4s 410us/step - loss: 0.0281 - accuracy: 0.9868\n",
      "Epoch 47/100\n",
      "8844/8844 [==============================] - 4s 409us/step - loss: 0.0372 - accuracy: 0.9855\n",
      "Epoch 48/100\n",
      "8844/8844 [==============================] - 4s 413us/step - loss: 0.0324 - accuracy: 0.9861\n",
      "2211/2211 [==============================] - 0s 63us/step\n",
      "\n",
      "Accuracy score of the Neural Network with TDLHBA hyperparameter settings 96.83%\n"
     ]
    }
   ],
   "source": [
    "history_TDLHBA = model_TDLHBA.fit(x_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model_TDLHBA.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with TDLHBA hyperparameter settings {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
