{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #1\n",
    "\n",
    "Get the first dataset with 30 attributes plus result from R. M. Mohammad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
       "0                 -1           1                   1                 1   \n",
       "1                  1           1                   1                 1   \n",
       "2                  1           0                   1                 1   \n",
       "3                  1           0                   1                 1   \n",
       "4                  1           0                  -1                 1   \n",
       "5                 -1           0                  -1                 1   \n",
       "6                  1           0                  -1                 1   \n",
       "7                  1           0                   1                 1   \n",
       "8                  1           0                  -1                 1   \n",
       "9                  1           1                  -1                 1   \n",
       "\n",
       "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
       "0                        -1             -1                 -1              -1   \n",
       "1                         1             -1                  0               1   \n",
       "2                         1             -1                 -1              -1   \n",
       "3                         1             -1                 -1              -1   \n",
       "4                         1             -1                  1               1   \n",
       "5                        -1             -1                  1               1   \n",
       "6                         1             -1                 -1              -1   \n",
       "7                         1             -1                 -1              -1   \n",
       "8                         1             -1                  1               1   \n",
       "9                         1             -1                 -1               1   \n",
       "\n",
       "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
       "0                           -1        1  ...            1       1   \n",
       "1                           -1        1  ...            1       1   \n",
       "2                           -1        1  ...            1       1   \n",
       "3                            1        1  ...            1       1   \n",
       "4                           -1        1  ...           -1       1   \n",
       "5                           -1        1  ...            1       1   \n",
       "6                            1        1  ...            1       1   \n",
       "7                            1        1  ...            1       1   \n",
       "8                           -1        1  ...            1       1   \n",
       "9                           -1        1  ...            1       1   \n",
       "\n",
       "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
       "0             -1         -1           -1         -1             1   \n",
       "1             -1         -1            0         -1             1   \n",
       "2              1         -1            1         -1             1   \n",
       "3             -1         -1            1         -1             1   \n",
       "4             -1         -1            0         -1             1   \n",
       "5              1          1            1         -1             1   \n",
       "6              1         -1           -1         -1             1   \n",
       "7             -1         -1            0         -1             1   \n",
       "8              1         -1            1          1             1   \n",
       "9              1         -1            0         -1             1   \n",
       "\n",
       "   Links_pointing_to_page  Statistical_report  Result  \n",
       "0                       1                  -1      -1  \n",
       "1                       1                   1      -1  \n",
       "2                       0                  -1      -1  \n",
       "3                      -1                   1      -1  \n",
       "4                       1                   1       1  \n",
       "5                      -1                  -1       1  \n",
       "6                       0                  -1      -1  \n",
       "7                       0                   1      -1  \n",
       "8                       0                   1       1  \n",
       "9                       0                   1      -1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url=\"./dataset1.csv\"\n",
    "df=pd.read_csv(url)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #1. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #1 : 11055\n",
      "Column count for dataset #1 : 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #1 :\", str(df.shape[0]))\n",
    "print(\"Column count for dataset #1 :\", str(df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #2\n",
    "\n",
    "Get the second dataset with 111 attributes plus result from Vrbančič."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0            3               0                  0              1   \n",
       "1            5               0                  1              3   \n",
       "2            2               0                  0              1   \n",
       "3            4               0                  2              5   \n",
       "4            2               0                  0              0   \n",
       "5            1               0                  0              2   \n",
       "6            2               0                  0              0   \n",
       "7            2               0                  0              3   \n",
       "8            2               0                  0              0   \n",
       "9            1               0                  0              2   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              3           0            2   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "5                     0              0           0            0   \n",
       "6                     0              0           0            0   \n",
       "7                     0              0           0            0   \n",
       "8                     0              0           0            0   \n",
       "9                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  qty_nameservers  \\\n",
       "0                    0              0  ...                1                2   \n",
       "1                    0              0  ...                1                2   \n",
       "2                    0              0  ...                1                2   \n",
       "3                    0              0  ...                1                2   \n",
       "4                    0              0  ...                1                2   \n",
       "5                    0              0  ...                1                3   \n",
       "6                    0              0  ...                1                2   \n",
       "7                    0              0  ...                1                2   \n",
       "8                    0              0  ...                1                4   \n",
       "9                    0              0  ...                1                2   \n",
       "\n",
       "   qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0               0           892                    0              0   \n",
       "1               1          9540                    1              0   \n",
       "2               3           589                    1              0   \n",
       "3               0           292                    1              0   \n",
       "4               1          3597                    0              1   \n",
       "5               3          3591                    1              0   \n",
       "6               2           291                    0              0   \n",
       "7               1          3134                    1              0   \n",
       "8               2          3596                    1              1   \n",
       "9               1         14397                    1              0   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  \n",
       "5                 0                    0              0         1  \n",
       "6                 0                    0              0         0  \n",
       "7                 0                    0              0         0  \n",
       "8                 0                    0              0         0  \n",
       "9                 0                    0              0         1  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2=\"./dataset2.csv\"\n",
    "df2=pd.read_csv(url2)\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #2. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #2 : 88647\n",
      "Column count for dataset #2 : 111\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #2 :\", str(df2.shape[0]))\n",
    "print(\"Column count for dataset #2 :\", str(df2.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #3\n",
    "\n",
    "The original paper Dataset #3 is inspired from describes using the following:\n",
    "\n",
    "    To train both models, a dataset of real and phishing URLs was constructed. In total, 2 million URLs were used in the training process. Half of them legitimate and half of them phishing. The legitimate URLs came from Common Crawl, a corpus of web crawl data. The phishing URLs came from Phishtank...\n",
    "    \n",
    "\n",
    "\n",
    "Using this dataset in place which is significantly smaller [this kaggle dataset](https://www.kaggle.com/kunal4892/phishingandlegitimateurls). We have 96,000 rows total as compared to the original experiment which contained 2 million rows. *Working on getting the original dataset to improve our results here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.voting-yahoo.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.zvon.org/xxl/WSDL1.1/Output/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tecportais.com/file-security-update-infonfmati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bima.astro.umd.edu/nemo/linuxastro/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>huarui-tec.com/js/?us.battle.net/login/en/?ref...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diannaopeizhi.com/js/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.synchrotech.com/support/install.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.ansi.okstate.edu/breeds/swine/largeblackwh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.strum.co.uk/webbery/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.grok2.com/vi-emacs.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              domain  label\n",
       "0                               www.voting-yahoo.com      1\n",
       "1         www.zvon.org/xxl/WSDL1.1/Output/index.html      0\n",
       "2  tecportais.com/file-security-update-infonfmati...      1\n",
       "3                bima.astro.umd.edu/nemo/linuxastro/      0\n",
       "4  huarui-tec.com/js/?us.battle.net/login/en/?ref...      1\n",
       "5                              diannaopeizhi.com/js/      1\n",
       "6           www.synchrotech.com/support/install.html      0\n",
       "7  www.ansi.okstate.edu/breeds/swine/largeblackwh...      0\n",
       "8                           www.strum.co.uk/webbery/      0\n",
       "9                        www.grok2.com/vi-emacs.html      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3=\"./dataset3.csv\"\n",
    "df3=pd.read_csv(url3)\n",
    "\n",
    "# Remove all columns except URL and label\n",
    "df3 = df3.drop(df3.columns[[1,2,3,4,5,6,7,8,9,10]], axis=1)\n",
    "\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #3 : 95910\n",
      "Column count for dataset #3 : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #3 :\", str(df3.shape[0]))\n",
    "print(\"Column count for dataset #3 :\", str(df3.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "On the first dataset convert value of -1 to 0 for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Result'].values[df['Result'].values < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will replace any missing values with the mean value for that column. This will be done for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use mean value for any nan values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df2.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split both of our datasets into section for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3 Converting to One-Hot Encoding\n",
    "\n",
    "***Note: due to time constraints we have not yet been able to reproduce LSTM with dataset #3. Using one-hot encoding with a dataset of this size requires to much RAM. A embedding layer on the Keras model is likely a better strategy. With more time we would like to explore this.***\n",
    "\n",
    "***The code in the cell below will likely produce an error as it requires over 18GB of RAM, please continue to the cell below it.***\n",
    "\n",
    "While datasets #1 and #2 are numeric, dataset #3 is simply a list URLs in string format. In order to prepare dataset #3 for our neural network we first have to convert it to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.3 GiB for an array with shape (95910, 2175, 94) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-8ff94fc507e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# build dataset with domains as one-hot encoded chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 18.3 GiB for an array with shape (95910, 2175, 94) and data type bool"
     ]
    }
   ],
   "source": [
    "# Make it all to a long string\n",
    "#concat_domains = '\\n'.join(df3['domain']).lower()\n",
    "concat_domains = '\\n'.join(df3['domain'])\n",
    "\n",
    "# Find all unique characters by using set()\n",
    "chars = sorted(list(set(concat_domains)))\n",
    "num_chars = len(chars)\n",
    "\n",
    "# Build translation dictionaries, 'a' -> 0, 0 -> 'a'\n",
    "char2idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Use longest name length as our sequence window\n",
    "max_sequence_length = max([len(name) for name in df3['domain']])\n",
    "\n",
    "# build dataset with domains as one-hot encoded chars\n",
    "X = np.zeros((df3.shape[0], max_sequence_length, num_chars), dtype=np.bool)\n",
    "y = df3['label'].values\n",
    "\n",
    "for i, sequence in enumerate(df3['domain']):\n",
    "    for j, char in enumerate(sequence):\n",
    "        X[i, j, char2idx[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the Data\n",
    "\n",
    "Next we need to seperate each dataset into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data up into training and test data\n",
    "x = df.iloc[:,0:30].values.astype(int)\n",
    "y = df.iloc[:,30].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x2 = df2.iloc[:,0:111].values.astype(int)\n",
    "y2 = df2.iloc[:,111].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x3 = df3.iloc[:,0:1].values.astype(str)\n",
    "y3 = df3.iloc[:,1].values.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Baseline Result\n",
    "\n",
    "Import `numpy` and set a random seed so that random values will be the same each time we run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a baseline comparision for our neural network we'll do a round of logitstic regression with a maximum iteration of 10,000. We'll use our training and test set from each dataset to get an accuracy score for both datasets while using logistic regression.\n",
    "\n",
    "This will be the baseline value to beat when using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_pred=logisticRegr.predict(x_test)\n",
    "\n",
    "logisticRegr2 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr2.fit(x_train2, y_train2)\n",
    "y_pred2=logisticRegr2.predict(x_test2)\n",
    "\n",
    "t = metrics.precision_recall_fscore_support(y_test, logisticRegr.predict(x_test), average='micro')\n",
    "t2 = metrics.precision_recall_fscore_support(y_test2, logisticRegr2.predict(x_test2), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision:\",metrics.precision_score(y_test2, y_pred2))\n",
    "print(\"Recall:\",metrics.recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #3\n",
    "\n",
    "As we've removed all attributes from our URLs for dataset #3 and are only left with a string for each row logistic regression will not be particularly useful as it requires first converting the string to a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Next we'll move to using our same datasets with a neural network. We're using 2 different rectified linear unit layers each with a slightly different amount of neurons. The results from these 2 layers arrives sequentially at the last layer sigmoid which produces a prediction. The sigmoid layer always produces a value between 0 and 1 which is useful in making our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "# This model actually seems to work better with higher numbers\n",
    "model.add(Dense(400, activation='softmax',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model.add(Dense(480, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #1\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "### 1 Layer\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | ---\n",
    "20 | 1 | 94.14%\n",
    "30 | 1 | 95.25%\n",
    "40 | 1 | 95.48%\n",
    "50 | 1 | 95.93%\n",
    "60 | 1 | 95.88%\n",
    "70 | 1 | 96.02%\n",
    "80 | 1 | 95.93%\n",
    "100 | 1 | 96.02%\n",
    "120 | 1 | 96.70%\n",
    "140 | 1 | 96.56%\n",
    "180 | 1 | 96.34%\n",
    "400 | 1 | 96.61%\n",
    "600 | 1 | 96.43%\n",
    "800 | 1 | 96.74%\n",
    "1000 | 1 | 96.65%\n",
    "1200 | 1 | 96.16%\n",
    "1600 | 1 | 96.34%\n",
    "2000 | 1 | 96.07%\n",
    "2200 | 1 | 96.65%\n",
    "**2300** | **1** | **97.11%**\n",
    "2400 | 1 | 96.83%\n",
    "3200 | 1 | 96.20%\n",
    "4600 | 1 | 96.56%\n",
    "6900 | 1 | 96.79%\n",
    "9200 | 1 | 96.74%\n",
    "11500 | 1 | 96.52%\n",
    "\n",
    "We took the best 2300 neurons result and ran it again 10 time.\n",
    "\n",
    "*96.47%, 97.01%, 96.34%, 96.56%, 96.70%, 96.43%, 96.88%, 96.38%, 96.83%, 96.92%*\n",
    "\n",
    "average = 96.652%\n",
    "\n",
    "We also took the second best result 2400 neurons and rain it again 5 times.\n",
    "\n",
    "*96.61%, 96.47%, 96.92, 96.61, 96.34%*\n",
    "\n",
    "average = 96.59%\n",
    "\n",
    "\n",
    "*While 2300 yielded the highest result, we attempted to run the model with 2300 again 5 seperate times and each time the result was under 97%.*\n",
    "\n",
    "### 2 Layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "30 | 40 | 1 | 95.52%\n",
    "40 | 30 | 1 | 91.30%\n",
    "30 | 50 | 1 | 91.30%\n",
    "40 | 50 | 1 | 95.66%\n",
    "50 | 60 | 1 | 96.20%\n",
    "60 | 70 | 1 | 91.30%\n",
    "100 | 120 | 1 | 96.25%\n",
    "200 | 240 | 1 | 96.47%\n",
    "**400** | **480** | **1** | **96.88%**\n",
    "800 | 960 | 1 | 96.70%\n",
    "1200 | 1300 | 1 | 91.30%\n",
    "1600 | 1920 | 1 | 96.79%\n",
    "3200 | 3840 | 1 | 96.83%\n",
    "6400 | 7680 | 1 | 96.61%\n",
    "6900 | 7680 | 1 | 96.38%\n",
    "12800 | 15360 | 1 | 96.11%\n",
    "\n",
    "We took the best result and ran it again 5 times. \n",
    "\n",
    "*96.70%, 96.97%, 97.29%, 96.83%, 96.61%, 96.16%, 96.92%, 96.25%, 96.34%, 96.83%*\n",
    "\n",
    "average = 96.69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 400)               12400     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 480)               192480    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 481       \n",
      "=================================================================\n",
      "Total params: 205,361\n",
      "Trainable params: 205,361\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "es_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 1s 135us/step - loss: 0.0619 - accuracy: 0.9750\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 1s 151us/step - loss: 0.0613 - accuracy: 0.9733\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0623 - accuracy: 0.9742\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 1s 126us/step - loss: 0.0590 - accuracy: 0.9764\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 1s 116us/step - loss: 0.0604 - accuracy: 0.9752\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 1s 134us/step - loss: 0.0594 - accuracy: 0.9755\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 1s 145us/step - loss: 0.0583 - accuracy: 0.9751\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 1s 138us/step - loss: 0.0568 - accuracy: 0.9767\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 1s 166us/step - loss: 0.0572 - accuracy: 0.9767\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 2s 199us/step - loss: 0.0562 - accuracy: 0.9769\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 1s 167us/step - loss: 0.0542 - accuracy: 0.9773\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 2s 171us/step - loss: 0.0543 - accuracy: 0.9768\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 1s 165us/step - loss: 0.0547 - accuracy: 0.9741\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 1s 118us/step - loss: 0.0533 - accuracy: 0.9766\n",
      "Epoch 15/128\n",
      "8844/8844 [==============================] - 1s 93us/step - loss: 0.0525 - accuracy: 0.9780\n",
      "Epoch 16/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0518 - accuracy: 0.9768\n",
      "Epoch 17/128\n",
      "8844/8844 [==============================] - 1s 97us/step - loss: 0.0522 - accuracy: 0.9775\n",
      "Epoch 18/128\n",
      "8844/8844 [==============================] - 1s 94us/step - loss: 0.0527 - accuracy: 0.9765\n",
      "Epoch 19/128\n",
      "8844/8844 [==============================] - 1s 102us/step - loss: 0.0501 - accuracy: 0.9790\n",
      "Epoch 20/128\n",
      "8844/8844 [==============================] - 1s 98us/step - loss: 0.0507 - accuracy: 0.9772\n",
      "Epoch 21/128\n",
      "8844/8844 [==============================] - 1s 104us/step - loss: 0.0507 - accuracy: 0.9774\n",
      "Epoch 22/128\n",
      "8844/8844 [==============================] - 1s 103us/step - loss: 0.0494 - accuracy: 0.9790\n",
      "Epoch 23/128\n",
      "8844/8844 [==============================] - 1s 102us/step - loss: 0.0489 - accuracy: 0.9801\n",
      "Epoch 24/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0486 - accuracy: 0.9787\n",
      "Epoch 25/128\n",
      "8844/8844 [==============================] - 1s 160us/step - loss: 0.0492 - accuracy: 0.9793\n",
      "Epoch 26/128\n",
      "8844/8844 [==============================] - 1s 127us/step - loss: 0.0493 - accuracy: 0.9778\n",
      "Epoch 27/128\n",
      "8844/8844 [==============================] - 1s 112us/step - loss: 0.0487 - accuracy: 0.9791\n",
      "Epoch 28/128\n",
      "8844/8844 [==============================] - 1s 115us/step - loss: 0.0476 - accuracy: 0.9800\n",
      "Epoch 29/128\n",
      "8844/8844 [==============================] - 1s 122us/step - loss: 0.0486 - accuracy: 0.9793\n",
      "Epoch 30/128\n",
      "8844/8844 [==============================] - 1s 114us/step - loss: 0.0464 - accuracy: 0.9791\n",
      "Epoch 31/128\n",
      "8844/8844 [==============================] - 1s 131us/step - loss: 0.0448 - accuracy: 0.9812\n",
      "Epoch 32/128\n",
      "8844/8844 [==============================] - 1s 112us/step - loss: 0.0441 - accuracy: 0.9806\n",
      "Epoch 33/128\n",
      "8844/8844 [==============================] - 1s 111us/step - loss: 0.0482 - accuracy: 0.9800\n",
      "Epoch 34/128\n",
      "8844/8844 [==============================] - 1s 127us/step - loss: 0.0451 - accuracy: 0.9801\n",
      "Epoch 35/128\n",
      "8844/8844 [==============================] - 1s 134us/step - loss: 0.0449 - accuracy: 0.9816\n",
      "Epoch 36/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0443 - accuracy: 0.9799\n",
      "2211/2211 [==============================] - 0s 53us/step\n",
      "\n",
      "Accuracy score of the Neural Network 96.47%\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building using the Sequential API\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x2.shape[1]))\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(160, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #2\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "111 | 135 | 1 | 92.70%\n",
    "135 | 111 | 1 | 92.55%\n",
    "135 | 135 | 1 | 93.16%\n",
    "145 | 111 | 1 | 92.30%\n",
    "222 | 270 | 1 | 93.18%\n",
    "**270** | **222** | **1** | **93.73%**\n",
    "450 | 600 | 1 | 93.53%\n",
    "540 | 444 | 1 | 91.84%\n",
    "600 | 450 | 1 | 92.79%\n",
    "600 | 500 | 1 | 92.24%\n",
    "666 | 777 | 1 | 91.89%\n",
    "900 | 1200 | 1 | 93.13%\n",
    "\n",
    "Trying with 2 instead of 3 layers.\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | --- \n",
    "111 | 1 | 92.30%\n",
    "135 | 1 | 93.05%\n",
    "270 | 1 | 92.38%\n",
    "**540** | **1** | **93.07%**\n",
    "1080 | 1 | 92.42%\n",
    "\n",
    "\n",
    "Trying with 4 instead of 3 layers.\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | Accuracy\n",
    "--- | --- | --- | --- | ---\n",
    "111 | 111 | 111 | 1 | 93.46%\n",
    "**135** | **135** | **135** | **1** | **93.92%**\n",
    "270 | 222 | 135 | 1 | 93.38%\n",
    "166 | 166 | 166 | 1 | 93.72%\n",
    "270 | 270 | 270 | 1 | 93.65%\n",
    "600 | 270 | 135 | 1 | 92.60%\n",
    "888 | 888 | 888 | 1 | 93.31%\n",
    "160 | 150 | 140 | 1 | 93.59%\n",
    "140 | 140 | 140 | 1 | 93.79%\n",
    "130 | 130 | 130 | 1 | 92.99%\n",
    "135 | 270 | 600 | 1 | 93.55%\n",
    "\n",
    "\n",
    "Trying with 5 layers\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | ---\n",
    "135 | 135 | 135 | 135 | 1 | 92.26%\n",
    "140 | 140 | 140 | 140 | 1 | 93.95%\n",
    "145 | 145 | 145 | 145 | 1 | 93.63%\n",
    "166 | 166 | 166 | 166 | 1 | 93.67%\n",
    "270 | 270 | 270 | 270 | 1 | 93.81%\n",
    "280 | 280 | 280 | 280 | 1 | 93.78%\n",
    "**135** | **270** | **500** | **1000** | **1** | **94.02%**\n",
    "135 | 270 | 540 | 1080 | 1 | 92.45%\n",
    "140 | 280 | 540 | 1080 | 1 | 93.50%\n",
    "270 | 560 | 1080 | 2160 | 1 | 93.07%\n",
    "\n",
    "Trying with 6 layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | L6 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | --- | ---\n",
    "140 | 140 | 140 | 140 | 140 | 1 | 94.03%\n",
    "145 | 145 | 145 | 145 | 145 | 1 | 94.35%\n",
    "**150** | **150** | **150** | **150** | **150** | **1** | **94.42%**\n",
    "155 | 155 | 155 | 155 | 155 | 1 | 94.17%\n",
    "160 | 160 | 160 | 160 | 160 | 1 | 93.34%\n",
    "135 | 270 | 500 | 1000 | 1000 | 1 | 93.53%\n",
    "1000 | 750 | 500 | 250 | 135 | 1 | --\n",
    "135 | 270 | 500 | 1000 | 2000 | 1 | 93.24%\n",
    "\n",
    "Trying with 7 layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | L6 Neurons | L7 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "150 | 150 | 150 | 150 | 150 | 150 | 1 | 93.87%\n",
    "**160** | **160** | **160** | **160** | **160** | **160** | **1** | **94.16%**\n",
    "170 | 170 | 170 | 170 | 170 | 170 | 1 | 93.90%\n",
    "180 | 180 | 180 | 180 | 180 | 180 | 1 | 93.64%\n",
    "222 | 222 | 222 | 222 | 222 | 222 | 1 | 94.01%\n",
    "333 | 333 | 333 | 333 | 333 | 333 | 1 | 94.02%\n",
    "444 | 444 | 444 | 444 | 444 | 444 | 1 | 92.05%\n",
    "555 | 555 | 555 | 555 | 555 | 555 | 1 | 94.02%\n",
    "666 | 666 | 666 | 666 | 666 | 666 | 1 | 93.05%\n",
    "135 | 270 | 540 | 1080 | 2160 | 4320 | 1 | --\n",
    "\n",
    "\n",
    "Trying with 8 layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | L6 Neurons | L7 Neurons | L8 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "160 | 160 | 160 | 160 | 160 | 160 | 160 | 1 | --\n",
    "170 | 170 | 170 | 170 | 170 | 170 | 170 | 1 | --\n",
    "180 | 180 | 180 | 180 | 180 | 180 | 180 | 1 | --\n",
    "222 | 222 | 222 | 222 | 222 | 222 | 222 | 1 | --\n",
    "444 | 444 | 444 | 444 | 444 | 444 | 444 | 1 | --\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 135)               15120     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 270)               36720     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 540)               146340    \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1080)              584280    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 1081      \n",
      "=================================================================\n",
      "Total params: 783,541\n",
      "Trainable params: 783,541\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "70917/70917 [==============================] - 8s 112us/step - loss: 0.4008 - accuracy: 0.8075\n",
      "Epoch 2/128\n",
      "70917/70917 [==============================] - 7s 104us/step - loss: 0.2419 - accuracy: 0.8985\n",
      "Epoch 3/128\n",
      "70917/70917 [==============================] - 7s 101us/step - loss: 0.2230 - accuracy: 0.9060\n",
      "Epoch 4/128\n",
      "70917/70917 [==============================] - 7s 97us/step - loss: 0.2150 - accuracy: 0.9101\n",
      "Epoch 5/128\n",
      "70917/70917 [==============================] - 7s 100us/step - loss: 0.2124 - accuracy: 0.9099\n",
      "Epoch 6/128\n",
      "70917/70917 [==============================] - 7s 99us/step - loss: 0.2026 - accuracy: 0.9141\n",
      "Epoch 7/128\n",
      "70917/70917 [==============================] - 8s 109us/step - loss: 0.2045 - accuracy: 0.9165\n",
      "Epoch 8/128\n",
      "70917/70917 [==============================] - 9s 124us/step - loss: 0.1977 - accuracy: 0.9181\n",
      "Epoch 9/128\n",
      "70917/70917 [==============================] - 7s 101us/step - loss: 0.1942 - accuracy: 0.9188\n",
      "Epoch 10/128\n",
      "70917/70917 [==============================] - 7s 103us/step - loss: 0.1889 - accuracy: 0.9210\n",
      "Epoch 11/128\n",
      "70917/70917 [==============================] - 9s 129us/step - loss: 0.1909 - accuracy: 0.9220\n",
      "Epoch 12/128\n",
      "70917/70917 [==============================] - 7s 98us/step - loss: 0.1843 - accuracy: 0.9239\n",
      "Epoch 13/128\n",
      "70917/70917 [==============================] - 7s 98us/step - loss: 0.1840 - accuracy: 0.9232\n",
      "Epoch 14/128\n",
      "70917/70917 [==============================] - 8s 111us/step - loss: 0.1818 - accuracy: 0.9255\n",
      "Epoch 15/128\n",
      "70917/70917 [==============================] - 8s 113us/step - loss: 0.1788 - accuracy: 0.9272\n",
      "Epoch 16/128\n",
      "70917/70917 [==============================] - 10s 138us/step - loss: 0.1790 - accuracy: 0.9266\n",
      "Epoch 17/128\n",
      "70917/70917 [==============================] - 10s 138us/step - loss: 0.1815 - accuracy: 0.9262\n",
      "Epoch 18/128\n",
      "70917/70917 [==============================] - 9s 122us/step - loss: 0.1922 - accuracy: 0.9236\n",
      "Epoch 19/128\n",
      "70917/70917 [==============================] - 9s 131us/step - loss: 0.1788 - accuracy: 0.9260\n",
      "Epoch 20/128\n",
      "70917/70917 [==============================] - 9s 128us/step - loss: 0.1754 - accuracy: 0.9283\n",
      "Epoch 21/128\n",
      "70917/70917 [==============================] - 9s 129us/step - loss: 0.1742 - accuracy: 0.9293\n",
      "Epoch 22/128\n",
      "70917/70917 [==============================] - 9s 133us/step - loss: 0.1742 - accuracy: 0.9297\n",
      "Epoch 23/128\n",
      "70917/70917 [==============================] - 9s 130us/step - loss: 0.1716 - accuracy: 0.9317\n",
      "Epoch 24/128\n",
      "70917/70917 [==============================] - 8s 119us/step - loss: 0.1683 - accuracy: 0.9331\n",
      "Epoch 25/128\n",
      "70917/70917 [==============================] - 8s 119us/step - loss: 0.1681 - accuracy: 0.9337\n",
      "Epoch 26/128\n",
      "70917/70917 [==============================] - 9s 122us/step - loss: 0.1681 - accuracy: 0.9332\n",
      "Epoch 27/128\n",
      "70917/70917 [==============================] - 9s 121us/step - loss: 0.1712 - accuracy: 0.9316\n",
      "Epoch 28/128\n",
      "70917/70917 [==============================] - 10s 136us/step - loss: 0.1653 - accuracy: 0.9350\n",
      "Epoch 29/128\n",
      "70917/70917 [==============================] - 11s 151us/step - loss: 0.1648 - accuracy: 0.9356\n",
      "Epoch 30/128\n",
      "70917/70917 [==============================] - 10s 140us/step - loss: 0.1640 - accuracy: 0.9362\n",
      "Epoch 31/128\n",
      "70917/70917 [==============================] - 10s 137us/step - loss: 0.1686 - accuracy: 0.9342\n",
      "Epoch 32/128\n",
      "70917/70917 [==============================] - 9s 126us/step - loss: 0.1634 - accuracy: 0.9354\n",
      "Epoch 33/128\n",
      "70917/70917 [==============================] - 8s 118us/step - loss: 0.1658 - accuracy: 0.9351\n",
      "Epoch 34/128\n",
      "70917/70917 [==============================] - 10s 140us/step - loss: 0.1649 - accuracy: 0.9359\n",
      "Epoch 35/128\n",
      "64448/70917 [==========================>...] - ETA: 0s - loss: 0.1621 - accuracy: 0.9369"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train2, y_train2, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores2 = model2.evaluate(x_test2, y_test2)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #3\n",
    "\n",
    "***Note: due to time constraints we have not yet been able to reproduce LSTM with dataset #3. The code in the cell below is not yet working.***\n",
    "\n",
    "***However the code further below related to Datasets #1 and #2 is working.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-90bfc48653fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Add a LSTM layer with 128 internal units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Add a Dense layer with 10 units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(10, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x3.shape[1]))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model3.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model3.add(layers.Dense(10))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Learning Rate Parameters\n",
    "\n",
    "In the 2 papers cited from Vrbančič et al. are mentioned hyperparameters including learning rate:\n",
    "\n",
    "*Vrbančič, Grega & Fister jr, Iztok & Podgorelec, Vili. (2019). Parameter Setting for Deep Neural Networks Using Swarm Intelligence on Phishing Websites Classification. International Journal on Artificial Intelligence Tools. 28. 1960008. 10.1142/S021821301960008X.*\n",
    "\n",
    "*Vrbančič, Grega & Fister jr, Iztok & Podgorelec, Vili. (2018). Swarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites Classification. 1-8. 10.1145/3227609.3227655.*\n",
    "\n",
    "In the first paper the following learning rates are listed based on algorithms:\n",
    "\n",
    "![](./images/learning-rate-paper-1.png)\n",
    "\n",
    "In the second paper the following learning rates are listed *(based on dataset #1 from Mohammad)*:\n",
    "\n",
    "![](./images/learning-rate-paper-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Learning Rate on Dataset #1 Neural Network\n",
    "\n",
    "Next we experiment by taking our best parameters from the previous experiments with dataset #1 and apply the suggested learning rate as well as other learning rates within the range of that suggested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(2300, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.01)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took the best configuration for the first dataset and attempted modifying it by adjusting the learning rate. We used rates in the range of that suggested by Vrbančič et al. in their paper from 2018. They suggested for neural networks a rate of `0.001` had the best result. We found that the best rate was...\n",
    "\n",
    "*Note: there is random vaience on each run, the numbers reported here are based on a single run for each setting.*\n",
    "\n",
    "\n",
    "However the performance did not increase from our previous results where we did not set a learning rate.\n",
    "\n",
    "With best 2 layer configuration:\n",
    "\n",
    "Learning Rate | Result\n",
    "--- | ---\n",
    "0.00005 | 96.92%\n",
    "0.0001 | 96.74%\n",
    "**0.0002** | **96.83%**\n",
    "0.0003 | 96.74%\n",
    "0.0004 | 96.20%\n",
    "0.001 | 96.16%\n",
    "0.01 | 94.89%\n",
    "\n",
    "With best 3 layer configuration:\n",
    "\n",
    "Learning Rate | Result\n",
    "--- | ---\n",
    "0.00002 | 96.65\n",
    "0.00004 | 96.79%\n",
    "0.00005 | 96.79%\n",
    "0.0001 | 96.74%\n",
    "**0.0002** | **96.97%**\n",
    "0.0003 | 96.83%\n",
    "0.0004 | 96.92%\n",
    "0.0005 | 96.47%\n",
    "0.0006 | 96.79%\n",
    "0.0008 | 96.56%\n",
    "0.001 | 96.16%\n",
    "0.0015 | 96.16%\n",
    "0.002 | 96.07%\n",
    "0.005 | 95.70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8844/8844 [==============================] - 3s 305us/step - loss: 0.2530 - accuracy: 0.9118\n",
      "Epoch 2/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.1761 - accuracy: 0.9346\n",
      "Epoch 3/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.1797 - accuracy: 0.9374\n",
      "Epoch 4/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.2881 - accuracy: 0.9350\n",
      "Epoch 5/100\n",
      "8844/8844 [==============================] - 2s 282us/step - loss: 0.1287 - accuracy: 0.9513\n",
      "Epoch 6/100\n",
      "8844/8844 [==============================] - 3s 286us/step - loss: 0.1145 - accuracy: 0.9566\n",
      "Epoch 7/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.1098 - accuracy: 0.9584\n",
      "Epoch 8/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.1002 - accuracy: 0.9607\n",
      "Epoch 9/100\n",
      "8844/8844 [==============================] - 3s 291us/step - loss: 0.1256 - accuracy: 0.9576\n",
      "Epoch 10/100\n",
      "8844/8844 [==============================] - 2s 283us/step - loss: 0.1129 - accuracy: 0.9619\n",
      "Epoch 11/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0928 - accuracy: 0.9643\n",
      "Epoch 12/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.0947 - accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "8844/8844 [==============================] - 3s 285us/step - loss: 0.0827 - accuracy: 0.9688\n",
      "Epoch 14/100\n",
      "8844/8844 [==============================] - 2s 282us/step - loss: 0.0998 - accuracy: 0.9637\n",
      "Epoch 15/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.0864 - accuracy: 0.9683\n",
      "Epoch 16/100\n",
      "8844/8844 [==============================] - 3s 286us/step - loss: 0.0815 - accuracy: 0.9714\n",
      "Epoch 17/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.0859 - accuracy: 0.9683\n",
      "Epoch 18/100\n",
      "8844/8844 [==============================] - 3s 284us/step - loss: 0.0836 - accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "8844/8844 [==============================] - 3s 288us/step - loss: 0.0727 - accuracy: 0.9678\n",
      "Epoch 20/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0703 - accuracy: 0.9716\n",
      "Epoch 21/100\n",
      "8844/8844 [==============================] - 2s 282us/step - loss: 0.0659 - accuracy: 0.9730\n",
      "Epoch 22/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0981 - accuracy: 0.9687\n",
      "Epoch 23/100\n",
      "8844/8844 [==============================] - 3s 286us/step - loss: 0.0902 - accuracy: 0.9725\n",
      "Epoch 24/100\n",
      "8844/8844 [==============================] - 3s 285us/step - loss: 0.1018 - accuracy: 0.9708\n",
      "Epoch 25/100\n",
      "8844/8844 [==============================] - 3s 290us/step - loss: 0.0916 - accuracy: 0.9713\n",
      "Epoch 26/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0727 - accuracy: 0.9734\n",
      "2211/2211 [==============================] - 0s 49us/step\n",
      "\n",
      "Accuracy score of the Neural Network with learning rate modified 94.89%\n"
     ]
    }
   ],
   "source": [
    "history_TDLHBA = model_TDLHBA.fit(x_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model_TDLHBA.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with learning rate modified {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Learning Rate on Dataset #2 Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA2 = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(2300, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.01)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
