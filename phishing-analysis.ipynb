{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #1\n",
    "\n",
    "Get the first dataset with 30 attributes plus result from R. M. Mohammad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>having_IP_Address</th>\n",
       "      <th>URL_Length</th>\n",
       "      <th>Shortining_Service</th>\n",
       "      <th>having_At_Symbol</th>\n",
       "      <th>double_slash_redirecting</th>\n",
       "      <th>Prefix_Suffix</th>\n",
       "      <th>having_Sub_Domain</th>\n",
       "      <th>SSLfinal_State</th>\n",
       "      <th>Domain_registeration_length</th>\n",
       "      <th>Favicon</th>\n",
       "      <th>...</th>\n",
       "      <th>popUpWidnow</th>\n",
       "      <th>Iframe</th>\n",
       "      <th>age_of_domain</th>\n",
       "      <th>DNSRecord</th>\n",
       "      <th>web_traffic</th>\n",
       "      <th>Page_Rank</th>\n",
       "      <th>Google_Index</th>\n",
       "      <th>Links_pointing_to_page</th>\n",
       "      <th>Statistical_report</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   having_IP_Address  URL_Length  Shortining_Service  having_At_Symbol  \\\n",
       "0                 -1           1                   1                 1   \n",
       "1                  1           1                   1                 1   \n",
       "2                  1           0                   1                 1   \n",
       "3                  1           0                   1                 1   \n",
       "4                  1           0                  -1                 1   \n",
       "5                 -1           0                  -1                 1   \n",
       "6                  1           0                  -1                 1   \n",
       "7                  1           0                   1                 1   \n",
       "8                  1           0                  -1                 1   \n",
       "9                  1           1                  -1                 1   \n",
       "\n",
       "   double_slash_redirecting  Prefix_Suffix  having_Sub_Domain  SSLfinal_State  \\\n",
       "0                        -1             -1                 -1              -1   \n",
       "1                         1             -1                  0               1   \n",
       "2                         1             -1                 -1              -1   \n",
       "3                         1             -1                 -1              -1   \n",
       "4                         1             -1                  1               1   \n",
       "5                        -1             -1                  1               1   \n",
       "6                         1             -1                 -1              -1   \n",
       "7                         1             -1                 -1              -1   \n",
       "8                         1             -1                  1               1   \n",
       "9                         1             -1                 -1               1   \n",
       "\n",
       "   Domain_registeration_length  Favicon  ...  popUpWidnow  Iframe  \\\n",
       "0                           -1        1  ...            1       1   \n",
       "1                           -1        1  ...            1       1   \n",
       "2                           -1        1  ...            1       1   \n",
       "3                            1        1  ...            1       1   \n",
       "4                           -1        1  ...           -1       1   \n",
       "5                           -1        1  ...            1       1   \n",
       "6                            1        1  ...            1       1   \n",
       "7                            1        1  ...            1       1   \n",
       "8                           -1        1  ...            1       1   \n",
       "9                           -1        1  ...            1       1   \n",
       "\n",
       "   age_of_domain  DNSRecord  web_traffic  Page_Rank  Google_Index  \\\n",
       "0             -1         -1           -1         -1             1   \n",
       "1             -1         -1            0         -1             1   \n",
       "2              1         -1            1         -1             1   \n",
       "3             -1         -1            1         -1             1   \n",
       "4             -1         -1            0         -1             1   \n",
       "5              1          1            1         -1             1   \n",
       "6              1         -1           -1         -1             1   \n",
       "7             -1         -1            0         -1             1   \n",
       "8              1         -1            1          1             1   \n",
       "9              1         -1            0         -1             1   \n",
       "\n",
       "   Links_pointing_to_page  Statistical_report  Result  \n",
       "0                       1                  -1      -1  \n",
       "1                       1                   1      -1  \n",
       "2                       0                  -1      -1  \n",
       "3                      -1                   1      -1  \n",
       "4                       1                   1       1  \n",
       "5                      -1                  -1       1  \n",
       "6                       0                  -1      -1  \n",
       "7                       0                   1      -1  \n",
       "8                       0                   1       1  \n",
       "9                       0                   1      -1  \n",
       "\n",
       "[10 rows x 31 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url=\"./dataset1.csv\"\n",
    "df=pd.read_csv(url)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #1. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #1 : 11055\n",
      "Column count for dataset #1 : 30\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #1 :\", str(df.shape[0]))\n",
    "print(\"Column count for dataset #1 :\", str(df.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #2\n",
    "\n",
    "Get the second dataset with 111 attributes plus result from Vrbančič."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qty_dot_url</th>\n",
       "      <th>qty_hyphen_url</th>\n",
       "      <th>qty_underline_url</th>\n",
       "      <th>qty_slash_url</th>\n",
       "      <th>qty_questionmark_url</th>\n",
       "      <th>qty_equal_url</th>\n",
       "      <th>qty_at_url</th>\n",
       "      <th>qty_and_url</th>\n",
       "      <th>qty_exclamation_url</th>\n",
       "      <th>qty_space_url</th>\n",
       "      <th>...</th>\n",
       "      <th>qty_ip_resolved</th>\n",
       "      <th>qty_nameservers</th>\n",
       "      <th>qty_mx_servers</th>\n",
       "      <th>ttl_hostname</th>\n",
       "      <th>tls_ssl_certificate</th>\n",
       "      <th>qty_redirects</th>\n",
       "      <th>url_google_index</th>\n",
       "      <th>domain_google_index</th>\n",
       "      <th>url_shortened</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>892</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9540</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>589</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>292</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3597</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3591</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>291</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3134</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3596</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14397</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 112 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qty_dot_url  qty_hyphen_url  qty_underline_url  qty_slash_url  \\\n",
       "0            3               0                  0              1   \n",
       "1            5               0                  1              3   \n",
       "2            2               0                  0              1   \n",
       "3            4               0                  2              5   \n",
       "4            2               0                  0              0   \n",
       "5            1               0                  0              2   \n",
       "6            2               0                  0              0   \n",
       "7            2               0                  0              3   \n",
       "8            2               0                  0              0   \n",
       "9            1               0                  0              2   \n",
       "\n",
       "   qty_questionmark_url  qty_equal_url  qty_at_url  qty_and_url  \\\n",
       "0                     0              0           0            0   \n",
       "1                     0              3           0            2   \n",
       "2                     0              0           0            0   \n",
       "3                     0              0           0            0   \n",
       "4                     0              0           0            0   \n",
       "5                     0              0           0            0   \n",
       "6                     0              0           0            0   \n",
       "7                     0              0           0            0   \n",
       "8                     0              0           0            0   \n",
       "9                     0              0           0            0   \n",
       "\n",
       "   qty_exclamation_url  qty_space_url  ...  qty_ip_resolved  qty_nameservers  \\\n",
       "0                    0              0  ...                1                2   \n",
       "1                    0              0  ...                1                2   \n",
       "2                    0              0  ...                1                2   \n",
       "3                    0              0  ...                1                2   \n",
       "4                    0              0  ...                1                2   \n",
       "5                    0              0  ...                1                3   \n",
       "6                    0              0  ...                1                2   \n",
       "7                    0              0  ...                1                2   \n",
       "8                    0              0  ...                1                4   \n",
       "9                    0              0  ...                1                2   \n",
       "\n",
       "   qty_mx_servers  ttl_hostname  tls_ssl_certificate  qty_redirects  \\\n",
       "0               0           892                    0              0   \n",
       "1               1          9540                    1              0   \n",
       "2               3           589                    1              0   \n",
       "3               0           292                    1              0   \n",
       "4               1          3597                    0              1   \n",
       "5               3          3591                    1              0   \n",
       "6               2           291                    0              0   \n",
       "7               1          3134                    1              0   \n",
       "8               2          3596                    1              1   \n",
       "9               1         14397                    1              0   \n",
       "\n",
       "   url_google_index  domain_google_index  url_shortened  phishing  \n",
       "0                 0                    0              0         1  \n",
       "1                 0                    0              0         1  \n",
       "2                 0                    0              0         0  \n",
       "3                 0                    0              0         1  \n",
       "4                 0                    0              0         0  \n",
       "5                 0                    0              0         1  \n",
       "6                 0                    0              0         0  \n",
       "7                 0                    0              0         0  \n",
       "8                 0                    0              0         0  \n",
       "9                 0                    0              0         1  \n",
       "\n",
       "[10 rows x 112 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url2=\"./dataset2.csv\"\n",
    "df2=pd.read_csv(url2)\n",
    "\n",
    "df2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the row and column count for dataset #2. *Column count is not including result.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #2 : 88647\n",
      "Column count for dataset #2 : 111\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #2 :\", str(df2.shape[0]))\n",
    "print(\"Column count for dataset #2 :\", str(df2.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset #3\n",
    "\n",
    "The original paper Dataset #3 is inspired from describes using the following:\n",
    "\n",
    "    To train both models, a dataset of real and phishing URLs was constructed. In total, 2 million URLs were used in the training process. Half of them legitimate and half of them phishing. The legitimate URLs came from Common Crawl, a corpus of web crawl data. The phishing URLs came from Phishtank...\n",
    "    \n",
    "\n",
    "\n",
    "Using this dataset in place which is significantly smaller [this kaggle dataset](https://www.kaggle.com/kunal4892/phishingandlegitimateurls). We have 96,000 rows total as compared to the original experiment which contained 2 million rows. *Working on getting the original dataset to improve our results here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.voting-yahoo.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.zvon.org/xxl/WSDL1.1/Output/index.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tecportais.com/file-security-update-infonfmati...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bima.astro.umd.edu/nemo/linuxastro/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>huarui-tec.com/js/?us.battle.net/login/en/?ref...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diannaopeizhi.com/js/</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>www.synchrotech.com/support/install.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>www.ansi.okstate.edu/breeds/swine/largeblackwh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>www.strum.co.uk/webbery/</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>www.grok2.com/vi-emacs.html</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              domain  label\n",
       "0                               www.voting-yahoo.com      1\n",
       "1         www.zvon.org/xxl/WSDL1.1/Output/index.html      0\n",
       "2  tecportais.com/file-security-update-infonfmati...      1\n",
       "3                bima.astro.umd.edu/nemo/linuxastro/      0\n",
       "4  huarui-tec.com/js/?us.battle.net/login/en/?ref...      1\n",
       "5                              diannaopeizhi.com/js/      1\n",
       "6           www.synchrotech.com/support/install.html      0\n",
       "7  www.ansi.okstate.edu/breeds/swine/largeblackwh...      0\n",
       "8                           www.strum.co.uk/webbery/      0\n",
       "9                        www.grok2.com/vi-emacs.html      0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url3=\"./dataset3.csv\"\n",
    "df3=pd.read_csv(url3)\n",
    "\n",
    "# Remove all columns except URL and label\n",
    "df3 = df3.drop(df3.columns[[1,2,3,4,5,6,7,8,9,10]], axis=1)\n",
    "\n",
    "df3.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count for dataset #3 : 95910\n",
      "Column count for dataset #3 : 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Row count for dataset #3 :\", str(df3.shape[0]))\n",
    "print(\"Column count for dataset #3 :\", str(df3.shape[1] - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "On the first dataset convert value of -1 to 0 for result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Result'].values[df['Result'].values < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will replace any missing values with the mean value for that column. This will be done for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Use mean value for any nan values\n",
    "df.fillna(df.mean(), inplace=True)\n",
    "df2.fillna(df.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will split both of our datasets into section for training and testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #3 Converting to One-Hot Encoding\n",
    "\n",
    "***Note: due to time constraints we have not yet been able to reproduce LSTM with dataset #3. Using one-hot encoding with a dataset of this size requires to much RAM. A embedding layer on the Keras model is likely a better strategy. With more time we would like to explore this.***\n",
    "\n",
    "***The code in the cell below will likely produce an error as it requires over 18GB of RAM, please continue to the cell below it.***\n",
    "\n",
    "While datasets #1 and #2 are numeric, dataset #3 is simply a list URLs in string format. In order to prepare dataset #3 for our neural network we first have to convert it to one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.3 GiB for an array with shape (95910, 2175, 94) and data type bool",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-8ff94fc507e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# build dataset with domains as one-hot encoded chars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_sequence_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_chars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 18.3 GiB for an array with shape (95910, 2175, 94) and data type bool"
     ]
    }
   ],
   "source": [
    "# Make it all to a long string\n",
    "#concat_domains = '\\n'.join(df3['domain']).lower()\n",
    "concat_domains = '\\n'.join(df3['domain'])\n",
    "\n",
    "# Find all unique characters by using set()\n",
    "chars = sorted(list(set(concat_domains)))\n",
    "num_chars = len(chars)\n",
    "\n",
    "# Build translation dictionaries, 'a' -> 0, 0 -> 'a'\n",
    "char2idx = dict((c, i) for i, c in enumerate(chars))\n",
    "idx2char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "# Use longest name length as our sequence window\n",
    "max_sequence_length = max([len(name) for name in df3['domain']])\n",
    "\n",
    "# build dataset with domains as one-hot encoded chars\n",
    "X = np.zeros((df3.shape[0], max_sequence_length, num_chars), dtype=np.bool)\n",
    "y = df3['label'].values\n",
    "\n",
    "for i, sequence in enumerate(df3['domain']):\n",
    "    for j, char in enumerate(sequence):\n",
    "        X[i, j, char2idx[char]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seperating the Data\n",
    "\n",
    "Next we need to seperate each dataset into training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# split data up into training and test data\n",
    "x = df.iloc[:,0:30].values.astype(int)\n",
    "y = df.iloc[:,30].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x2 = df2.iloc[:,0:111].values.astype(int)\n",
    "y2 = df2.iloc[:,111].values.astype(int)\n",
    "\n",
    "# split data up into training and test data\n",
    "x3 = df3.iloc[:,0:1].values.astype(str)\n",
    "y3 = df3.iloc[:,1].values.astype(str)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(x2, y2, test_size=0.2, random_state=42)\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(x3, y3, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression as a Baseline Result\n",
    "\n",
    "Import `numpy` and set a random seed so that random values will be the same each time we run this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to create a baseline comparision for our neural network we'll do a round of logitstic regression with a maximum iteration of 10,000. We'll use our training and test set from each dataset to get an accuracy score for both datasets while using logistic regression.\n",
    "\n",
    "This will be the baseline value to beat when using a neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "logisticRegr = LogisticRegression(max_iter=10000)\n",
    "logisticRegr.fit(x_train, y_train)\n",
    "y_pred=logisticRegr.predict(x_test)\n",
    "\n",
    "logisticRegr2 = LogisticRegression(max_iter=10000)\n",
    "logisticRegr2.fit(x_train2, y_train2)\n",
    "y_pred2=logisticRegr2.predict(x_test2)\n",
    "\n",
    "t = metrics.precision_recall_fscore_support(y_test, logisticRegr.predict(x_test), average='micro')\n",
    "t2 = metrics.precision_recall_fscore_support(y_test2, logisticRegr2.predict(x_test2), average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test2, y_pred2))\n",
    "print(\"Precision:\",metrics.precision_score(y_test2, y_pred2))\n",
    "print(\"Recall:\",metrics.recall_score(y_test2, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result for Logistic Regression with Dataset #3\n",
    "\n",
    "As we've removed all attributes from our URLs for dataset #3 and are only left with a string for each row logistic regression will not be particularly useful as it requires first converting the string to a float."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Next we'll move to using our same datasets with a neural network. We're using 2 different rectified linear unit layers each with a slightly different amount of neurons. The results from these 2 layers arrives sequentially at the last layer sigmoid which produces a prediction. The sigmoid layer always produces a value between 0 and 1 which is useful in making our prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Dataset #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(2300, activation='softmax',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #1\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "### 1 Layer\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | ---\n",
    "20 | 1 | 94.14%\n",
    "30 | 1 | 95.25%\n",
    "40 | 1 | 95.48%\n",
    "50 | 1 | 95.93%\n",
    "60 | 1 | 95.88%\n",
    "70 | 1 | 96.02%\n",
    "80 | 1 | 95.93%\n",
    "100 | 1 | 96.02%\n",
    "120 | 1 | 96.70%\n",
    "140 | 1 | 96.56%\n",
    "180 | 1 | 96.34%\n",
    "400 | 1 | 96.61%\n",
    "600 | 1 | 96.43%\n",
    "800 | 1 | 96.74%\n",
    "1000 | 1 | 96.65%\n",
    "1200 | 1 | 96.16%\n",
    "1600 | 1 | 96.34%\n",
    "2000 | 1 | 96.07%\n",
    "2200 | 1 | 96.65%\n",
    "**2300** | **1** | **97.11%**\n",
    "2400 | 1 | 96.83%\n",
    "3200 | 1 | 96.20%\n",
    "4600 | 1 | 96.56%\n",
    "6900 | 1 | 96.79%\n",
    "9200 | 1 | 96.74%\n",
    "11500 | 1 | 96.52%\n",
    "\n",
    "We took the best 2300 neurons result and ran it again 10 time.\n",
    "\n",
    "*96.47%, 97.01%, 96.34%, 96.56%, 96.70%, 96.43%, 96.88%, 96.38%, 96.83%, 96.92%*\n",
    "\n",
    "average = 96.652%\n",
    "\n",
    "We also took the second best result 2400 neurons and rain it again 5 times.\n",
    "\n",
    "*96.61%, 96.47%, 96.92, 96.61, 96.34%*\n",
    "\n",
    "average = 96.59%\n",
    "\n",
    "\n",
    "*While 2300 yielded the highest result, we attempted to run the model with 2300 again 5 seperate times and each time the result was under 97%.*\n",
    "\n",
    "### 2 Layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "30 | 40 | 1 | 95.52%\n",
    "40 | 30 | 1 | 91.30%\n",
    "30 | 50 | 1 | 91.30%\n",
    "40 | 50 | 1 | 95.66%\n",
    "50 | 60 | 1 | 96.20%\n",
    "60 | 70 | 1 | 91.30%\n",
    "100 | 120 | 1 | 96.25%\n",
    "200 | 240 | 1 | 96.47%\n",
    "**400** | **480** | **1** | **96.88%**\n",
    "800 | 960 | 1 | 96.70%\n",
    "1200 | 1300 | 1 | 91.30%\n",
    "1600 | 1920 | 1 | 96.79%\n",
    "3200 | 3840 | 1 | 96.83%\n",
    "6400 | 7680 | 1 | 96.61%\n",
    "6900 | 7680 | 1 | 96.38%\n",
    "12800 | 15360 | 1 | 96.11%\n",
    "\n",
    "We took the best result and ran it again 5 times. \n",
    "\n",
    "*96.70%, 96.97%, 97.29%, 96.83%, 96.61%, 96.16%, 96.92%, 96.25%, 96.34%, 96.83%*\n",
    "\n",
    "average = 96.69%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_49\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_206 (Dense)            (None, 2300)              71300     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 1)                 2301      \n",
      "=================================================================\n",
      "Total params: 73,601\n",
      "Trainable params: 73,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import callbacks\n",
    "\n",
    "es_cb = callbacks.EarlyStopping(monitor='loss', min_delta=0.001, patience=5, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #1 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "8844/8844 [==============================] - 1s 135us/step - loss: 0.0619 - accuracy: 0.9750\n",
      "Epoch 2/128\n",
      "8844/8844 [==============================] - 1s 151us/step - loss: 0.0613 - accuracy: 0.9733\n",
      "Epoch 3/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0623 - accuracy: 0.9742\n",
      "Epoch 4/128\n",
      "8844/8844 [==============================] - 1s 126us/step - loss: 0.0590 - accuracy: 0.9764\n",
      "Epoch 5/128\n",
      "8844/8844 [==============================] - 1s 116us/step - loss: 0.0604 - accuracy: 0.9752\n",
      "Epoch 6/128\n",
      "8844/8844 [==============================] - 1s 134us/step - loss: 0.0594 - accuracy: 0.9755\n",
      "Epoch 7/128\n",
      "8844/8844 [==============================] - 1s 145us/step - loss: 0.0583 - accuracy: 0.9751\n",
      "Epoch 8/128\n",
      "8844/8844 [==============================] - 1s 138us/step - loss: 0.0568 - accuracy: 0.9767\n",
      "Epoch 9/128\n",
      "8844/8844 [==============================] - 1s 166us/step - loss: 0.0572 - accuracy: 0.9767\n",
      "Epoch 10/128\n",
      "8844/8844 [==============================] - 2s 199us/step - loss: 0.0562 - accuracy: 0.9769\n",
      "Epoch 11/128\n",
      "8844/8844 [==============================] - 1s 167us/step - loss: 0.0542 - accuracy: 0.9773\n",
      "Epoch 12/128\n",
      "8844/8844 [==============================] - 2s 171us/step - loss: 0.0543 - accuracy: 0.9768\n",
      "Epoch 13/128\n",
      "8844/8844 [==============================] - 1s 165us/step - loss: 0.0547 - accuracy: 0.9741\n",
      "Epoch 14/128\n",
      "8844/8844 [==============================] - 1s 118us/step - loss: 0.0533 - accuracy: 0.9766\n",
      "Epoch 15/128\n",
      "8844/8844 [==============================] - 1s 93us/step - loss: 0.0525 - accuracy: 0.9780\n",
      "Epoch 16/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0518 - accuracy: 0.9768\n",
      "Epoch 17/128\n",
      "8844/8844 [==============================] - 1s 97us/step - loss: 0.0522 - accuracy: 0.9775\n",
      "Epoch 18/128\n",
      "8844/8844 [==============================] - 1s 94us/step - loss: 0.0527 - accuracy: 0.9765\n",
      "Epoch 19/128\n",
      "8844/8844 [==============================] - 1s 102us/step - loss: 0.0501 - accuracy: 0.9790\n",
      "Epoch 20/128\n",
      "8844/8844 [==============================] - 1s 98us/step - loss: 0.0507 - accuracy: 0.9772\n",
      "Epoch 21/128\n",
      "8844/8844 [==============================] - 1s 104us/step - loss: 0.0507 - accuracy: 0.9774\n",
      "Epoch 22/128\n",
      "8844/8844 [==============================] - 1s 103us/step - loss: 0.0494 - accuracy: 0.9790\n",
      "Epoch 23/128\n",
      "8844/8844 [==============================] - 1s 102us/step - loss: 0.0489 - accuracy: 0.9801\n",
      "Epoch 24/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0486 - accuracy: 0.9787\n",
      "Epoch 25/128\n",
      "8844/8844 [==============================] - 1s 160us/step - loss: 0.0492 - accuracy: 0.9793\n",
      "Epoch 26/128\n",
      "8844/8844 [==============================] - 1s 127us/step - loss: 0.0493 - accuracy: 0.9778\n",
      "Epoch 27/128\n",
      "8844/8844 [==============================] - 1s 112us/step - loss: 0.0487 - accuracy: 0.9791\n",
      "Epoch 28/128\n",
      "8844/8844 [==============================] - 1s 115us/step - loss: 0.0476 - accuracy: 0.9800\n",
      "Epoch 29/128\n",
      "8844/8844 [==============================] - 1s 122us/step - loss: 0.0486 - accuracy: 0.9793\n",
      "Epoch 30/128\n",
      "8844/8844 [==============================] - 1s 114us/step - loss: 0.0464 - accuracy: 0.9791\n",
      "Epoch 31/128\n",
      "8844/8844 [==============================] - 1s 131us/step - loss: 0.0448 - accuracy: 0.9812\n",
      "Epoch 32/128\n",
      "8844/8844 [==============================] - 1s 112us/step - loss: 0.0441 - accuracy: 0.9806\n",
      "Epoch 33/128\n",
      "8844/8844 [==============================] - 1s 111us/step - loss: 0.0482 - accuracy: 0.9800\n",
      "Epoch 34/128\n",
      "8844/8844 [==============================] - 1s 127us/step - loss: 0.0451 - accuracy: 0.9801\n",
      "Epoch 35/128\n",
      "8844/8844 [==============================] - 1s 134us/step - loss: 0.0449 - accuracy: 0.9816\n",
      "Epoch 36/128\n",
      "8844/8844 [==============================] - 1s 110us/step - loss: 0.0443 - accuracy: 0.9799\n",
      "2211/2211 [==============================] - 0s 53us/step\n",
      "\n",
      "Accuracy score of the Neural Network 96.47%\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network for Dataset #2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model building using the Sequential API\n",
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x2.shape[1]))\n",
    "model2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model2.add(Dense(1,  activation='sigmoid',\n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "model2.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #2\n",
    "\n",
    "We have experimented with a variety of values for the dense layers above.\n",
    "\n",
    "*Running the same parameters multiple times can result in slightly different results.*\n",
    "\n",
    "***Due to time constraints we couldn't run as many neuron combinations as we would have liked esspecially for the tables including several layers.***\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | Accuracy\n",
    "--- | --- | --- | ---\n",
    "111 | 135 | 1 | 92.70%\n",
    "135 | 111 | 1 | 92.55%\n",
    "135 | 135 | 1 | 93.16%\n",
    "145 | 111 | 1 | 92.30%\n",
    "222 | 270 | 1 | 93.18%\n",
    "**270** | **222** | **1** | **93.73%**\n",
    "450 | 600 | 1 | 93.53%\n",
    "540 | 444 | 1 | 91.84%\n",
    "600 | 450 | 1 | 92.79%\n",
    "600 | 500 | 1 | 92.24%\n",
    "666 | 777 | 1 | 91.89%\n",
    "900 | 1200 | 1 | 93.13%\n",
    "\n",
    "Trying with 2 instead of 3 layers.\n",
    "\n",
    "L1 Neurons | L2 Neurons | Accuracy\n",
    "--- | --- | --- \n",
    "111 | 1 | 92.30%\n",
    "135 | 1 | 93.05%\n",
    "270 | 1 | 92.38%\n",
    "**540** | **1** | **93.07%**\n",
    "1080 | 1 | 92.42%\n",
    "\n",
    "\n",
    "Trying with 4 instead of 3 layers.\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | Accuracy\n",
    "--- | --- | --- | --- | ---\n",
    "111 | 111 | 111 | 1 | 93.46%\n",
    "**135** | **135** | **135** | **1** | **93.92%**\n",
    "270 | 222 | 135 | 1 | 93.38%\n",
    "166 | 166 | 166 | 1 | 93.72%\n",
    "270 | 270 | 270 | 1 | 93.65%\n",
    "600 | 270 | 135 | 1 | 92.60%\n",
    "888 | 888 | 888 | 1 | 93.31%\n",
    "160 | 150 | 140 | 1 | 93.59%\n",
    "140 | 140 | 140 | 1 | 93.79%\n",
    "130 | 130 | 130 | 1 | 92.99%\n",
    "135 | 270 | 600 | 1 | 93.55%\n",
    "\n",
    "\n",
    "Trying with 5 layers\n",
    "\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | ---\n",
    "135 | 135 | 135 | 135 | 1 | 92.26%\n",
    "140 | 140 | 140 | 140 | 1 | 93.95%\n",
    "145 | 145 | 145 | 145 | 1 | 93.63%\n",
    "166 | 166 | 166 | 166 | 1 | 93.67%\n",
    "270 | 270 | 270 | 270 | 1 | 93.81%\n",
    "280 | 280 | 280 | 280 | 1 | 93.78%\n",
    "**135** | **270** | **500** | **1000** | **1** | **94.02%**\n",
    "135 | 270 | 540 | 1080 | 1 | 92.45%\n",
    "140 | 280 | 540 | 1080 | 1 | 93.50%\n",
    "270 | 560 | 1080 | 2160 | 1 | 93.07%\n",
    "\n",
    "Trying with 6 layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | L6 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | --- | ---\n",
    "140 | 140 | 140 | 140 | 140 | 1 | 94.03%\n",
    "145 | 145 | 145 | 145 | 145 | 1 | 94.35%\n",
    "**150** | **150** | **150** | **150** | **150** | **1** | **94.42%**\n",
    "155 | 155 | 155 | 155 | 155 | 1 | 94.17%\n",
    "160 | 160 | 160 | 160 | 160 | 1 | 93.34%\n",
    "135 | 270 | 500 | 1000 | 1000 | 1 | 93.53%\n",
    "1000 | 750 | 500 | 250 | 135 | 1 | --\n",
    "135 | 270 | 500 | 1000 | 2000 | 1 | 93.24%\n",
    "\n",
    "Trying with 7 layers\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | L6 Neurons | L7 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | --- | --- | ---\n",
    "150 | 150 | 150 | 150 | 150 | 150 | 1 | 93.87%\n",
    "**160** | **160** | **160** | **160** | **160** | **160** | **1** | **94.16%**\n",
    "170 | 170 | 170 | 170 | 170 | 170 | 1 | 93.90%\n",
    "180 | 180 | 180 | 180 | 180 | 180 | 1 | 93.64%\n",
    "222 | 222 | 222 | 222 | 222 | 222 | 1 | 94.01%\n",
    "333 | 333 | 333 | 333 | 333 | 333 | 1 | 94.02%\n",
    "444 | 444 | 444 | 444 | 444 | 444 | 1 | 92.05%\n",
    "555 | 555 | 555 | 555 | 555 | 555 | 1 | 94.02%\n",
    "666 | 666 | 666 | 666 | 666 | 666 | 1 | 93.05%\n",
    "135 | 270 | 540 | 1080 | 2160 | 4320 | 1 | --\n",
    "\n",
    "\n",
    "Trying with 8 layers\n",
    "\n",
    "*only had time for a few due to time constains*\n",
    "\n",
    "L1 Neurons | L2 Neurons | L3 Neurons | L4 Neurons | L5 Neurons | L6 Neurons | L7 Neurons | L8 Neurons | Accuracy\n",
    "--- | --- | --- | --- | --- | --- | --- | --- | ---\n",
    "160 | 160 | 160 | 160 | 160 | 160 | 160 | 1 | 93.54%\n",
    "170 | 170 | 170 | 170 | 170 | 170 | 170 | 1 | --\n",
    "180 | 180 | 180 | 180 | 180 | 180 | 180 | 1 | 92.32%\n",
    "222 | 222 | 222 | 222 | 222 | 222 | 222 | 1 | --\n",
    "444 | 444 | 444 | 444 | 444 | 444 | 444 | 1 | --\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_50\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_208 (Dense)            (None, 150)               16800     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 150)               22650     \n",
      "_________________________________________________________________\n",
      "dense_213 (Dense)            (None, 1)                 151       \n",
      "=================================================================\n",
      "Total params: 107,551\n",
      "Trainable params: 107,551\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model #2 Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "keras.utils.plot_model(model2, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/128\n",
      "70917/70917 [==============================] - 9s 132us/step - loss: 0.3846 - accuracy: 0.8198\n",
      "Epoch 2/128\n",
      "70917/70917 [==============================] - 8s 119us/step - loss: 0.2385 - accuracy: 0.9006\n",
      "Epoch 3/128\n",
      "70917/70917 [==============================] - 8s 114us/step - loss: 0.2240 - accuracy: 0.9061\n",
      "Epoch 4/128\n",
      "70917/70917 [==============================] - 9s 129us/step - loss: 0.2178 - accuracy: 0.9085\n",
      "Epoch 5/128\n",
      "70917/70917 [==============================] - 9s 124us/step - loss: 0.2139 - accuracy: 0.9098\n",
      "Epoch 6/128\n",
      "70917/70917 [==============================] - 9s 123us/step - loss: 0.2076 - accuracy: 0.9127\n",
      "Epoch 7/128\n",
      "70917/70917 [==============================] - 9s 129us/step - loss: 0.2052 - accuracy: 0.9123\n",
      "Epoch 8/128\n",
      "70917/70917 [==============================] - 9s 125us/step - loss: 0.2016 - accuracy: 0.9132\n",
      "Epoch 9/128\n",
      "70917/70917 [==============================] - 12s 170us/step - loss: 0.2058 - accuracy: 0.9128\n",
      "Epoch 10/128\n",
      "70917/70917 [==============================] - 11s 156us/step - loss: 0.1976 - accuracy: 0.9184\n",
      "Epoch 11/128\n",
      "70917/70917 [==============================] - 10s 140us/step - loss: 0.1902 - accuracy: 0.9199\n",
      "Epoch 12/128\n",
      "70917/70917 [==============================] - 10s 136us/step - loss: 0.1888 - accuracy: 0.9214\n",
      "Epoch 13/128\n",
      "70917/70917 [==============================] - 10s 138us/step - loss: 0.1882 - accuracy: 0.9209\n",
      "Epoch 14/128\n",
      "70917/70917 [==============================] - 9s 133us/step - loss: 0.1871 - accuracy: 0.9223\n",
      "Epoch 15/128\n",
      "70917/70917 [==============================] - 9s 130us/step - loss: 0.1867 - accuracy: 0.9221\n",
      "Epoch 16/128\n",
      "70917/70917 [==============================] - 9s 124us/step - loss: 0.1822 - accuracy: 0.9250\n",
      "Epoch 17/128\n",
      "70917/70917 [==============================] - 9s 126us/step - loss: 0.1826 - accuracy: 0.9248\n",
      "Epoch 18/128\n",
      "70917/70917 [==============================] - 11s 148us/step - loss: 0.1827 - accuracy: 0.9248\n",
      "Epoch 19/128\n",
      "70917/70917 [==============================] - 11s 154us/step - loss: 0.1836 - accuracy: 0.9237\n",
      "Epoch 20/128\n",
      "70917/70917 [==============================] - 11s 149us/step - loss: 0.1845 - accuracy: 0.9244\n",
      "Epoch 21/128\n",
      "70917/70917 [==============================] - 11s 161us/step - loss: 0.1816 - accuracy: 0.9251\n",
      "17730/17730 [==============================] - 1s 71us/step\n",
      "\n",
      "Accuracy score of the Neural Network 92.32%\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(x_train2, y_train2, batch_size=64, epochs=128, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores2 = model2.evaluate(x_test2, y_test2)\n",
    "print('\\nAccuracy score of the Neural Network {0:.2f}%'.format(scores2[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Neurons and Layers for Dataset #3\n",
    "\n",
    "***Note: due to time constraints we have not yet been able to reproduce LSTM with dataset #3. The code in the cell below is not yet working.***\n",
    "\n",
    "***However the code further below related to Datasets #1 and #2 is working.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-100-90bfc48653fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Add a LSTM layer with 128 internal units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mmodel3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Add a Dense layer with 10 units.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    180\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_source_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m             \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 raise TypeError('All layers in a Sequential model '\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/layers/recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36msymbolic_fn_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_SYMBOLIC_SCOPE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mget_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[1;32m    444\u001b[0m                 \u001b[0;31m# Raise exceptions in case the input is not compatible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;31m# with the input_spec specified in the layer constructor.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 446\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_input_compatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m                 \u001b[0;31m# Collect input shapes to build layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                                      \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': expected ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                                      \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m', found ndim='\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                                      str(K.ndim(x)))\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                 \u001b[0mndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input 0 is incompatible with layer lstm_1: expected ndim=3, found ndim=2"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import layers\n",
    "from keras.optimizers import *\n",
    "\n",
    "# Model building using the Sequential API\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(10, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x3.shape[1]))\n",
    "\n",
    "# Add a LSTM layer with 128 internal units.\n",
    "model3.add(layers.LSTM(128))\n",
    "\n",
    "# Add a Dense layer with 10 units.\n",
    "model3.add(layers.Dense(10))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimenting with Learning Rate Parameters\n",
    "\n",
    "In the 2 papers cited from Vrbančič et al. are mentioned hyperparameters including learning rate:\n",
    "\n",
    "*Vrbančič, Grega & Fister jr, Iztok & Podgorelec, Vili. (2019). Parameter Setting for Deep Neural Networks Using Swarm Intelligence on Phishing Websites Classification. International Journal on Artificial Intelligence Tools. 28. 1960008. 10.1142/S021821301960008X.*\n",
    "\n",
    "*Vrbančič, Grega & Fister jr, Iztok & Podgorelec, Vili. (2018). Swarm Intelligence Approaches for Parameter Setting of Deep Learning Neural Network: Case Study on Phishing Websites Classification. 1-8. 10.1145/3227609.3227655.*\n",
    "\n",
    "In the first paper the following learning rates are listed based on algorithms:\n",
    "\n",
    "![](./images/learning-rate-paper-1.png)\n",
    "\n",
    "In the second paper the following learning rates are listed *(based on dataset #1 from Mohammad)*:\n",
    "\n",
    "![](./images/learning-rate-paper-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Learning Rate on Dataset #1 Neural Network\n",
    "\n",
    "Next we experiment by taking our best parameters from the previous experiments with dataset #1 and apply the suggested learning rate as well as other learning rates within the range of that suggested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA = Sequential()\n",
    "\n",
    "model_TDLHBA.add(Dense(2300, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x.shape[1]))\n",
    "model_TDLHBA.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.01)\n",
    "model_TDLHBA.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We took the best configuration for the first dataset and attempted modifying it by adjusting the learning rate. We used rates in the range of that suggested by Vrbančič et al. in their paper from 2018. They suggested for neural networks a rate of `0.001` had the best result. We found that the best rate was...\n",
    "\n",
    "*Note: there is random vaience on each run, the numbers reported here are based on a single run for each setting.*\n",
    "\n",
    "\n",
    "However the performance did not increase from our previous results where we did not set a learning rate.\n",
    "\n",
    "With best 2 layer configuration:\n",
    "\n",
    "Learning Rate | Result\n",
    "--- | ---\n",
    "0.00005 | 96.92%\n",
    "0.0001 | 96.74%\n",
    "**0.0002** | **96.83%**\n",
    "0.0003 | 96.74%\n",
    "0.0004 | 96.20%\n",
    "0.001 | 96.16%\n",
    "0.01 | 94.89%\n",
    "\n",
    "With best 3 layer configuration:\n",
    "\n",
    "Learning Rate | Result\n",
    "--- | ---\n",
    "0.00002 | 96.65\n",
    "0.00004 | 96.79%\n",
    "0.00005 | 96.79%\n",
    "0.0001 | 96.74%\n",
    "**0.0002** | **96.97%**\n",
    "0.0003 | 96.83%\n",
    "0.0004 | 96.92%\n",
    "0.0005 | 96.47%\n",
    "0.0006 | 96.79%\n",
    "0.0008 | 96.56%\n",
    "0.001 | 96.16%\n",
    "0.0015 | 96.16%\n",
    "0.002 | 96.07%\n",
    "0.005 | 95.70%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "8844/8844 [==============================] - 3s 305us/step - loss: 0.2530 - accuracy: 0.9118\n",
      "Epoch 2/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.1761 - accuracy: 0.9346\n",
      "Epoch 3/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.1797 - accuracy: 0.9374\n",
      "Epoch 4/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.2881 - accuracy: 0.9350\n",
      "Epoch 5/100\n",
      "8844/8844 [==============================] - 2s 282us/step - loss: 0.1287 - accuracy: 0.9513\n",
      "Epoch 6/100\n",
      "8844/8844 [==============================] - 3s 286us/step - loss: 0.1145 - accuracy: 0.9566\n",
      "Epoch 7/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.1098 - accuracy: 0.9584\n",
      "Epoch 8/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.1002 - accuracy: 0.9607\n",
      "Epoch 9/100\n",
      "8844/8844 [==============================] - 3s 291us/step - loss: 0.1256 - accuracy: 0.9576\n",
      "Epoch 10/100\n",
      "8844/8844 [==============================] - 2s 283us/step - loss: 0.1129 - accuracy: 0.9619\n",
      "Epoch 11/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0928 - accuracy: 0.9643\n",
      "Epoch 12/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.0947 - accuracy: 0.9653\n",
      "Epoch 13/100\n",
      "8844/8844 [==============================] - 3s 285us/step - loss: 0.0827 - accuracy: 0.9688\n",
      "Epoch 14/100\n",
      "8844/8844 [==============================] - 2s 282us/step - loss: 0.0998 - accuracy: 0.9637\n",
      "Epoch 15/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.0864 - accuracy: 0.9683\n",
      "Epoch 16/100\n",
      "8844/8844 [==============================] - 3s 286us/step - loss: 0.0815 - accuracy: 0.9714\n",
      "Epoch 17/100\n",
      "8844/8844 [==============================] - 3s 283us/step - loss: 0.0859 - accuracy: 0.9683\n",
      "Epoch 18/100\n",
      "8844/8844 [==============================] - 3s 284us/step - loss: 0.0836 - accuracy: 0.9694\n",
      "Epoch 19/100\n",
      "8844/8844 [==============================] - 3s 288us/step - loss: 0.0727 - accuracy: 0.9678\n",
      "Epoch 20/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0703 - accuracy: 0.9716\n",
      "Epoch 21/100\n",
      "8844/8844 [==============================] - 2s 282us/step - loss: 0.0659 - accuracy: 0.9730\n",
      "Epoch 22/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0981 - accuracy: 0.9687\n",
      "Epoch 23/100\n",
      "8844/8844 [==============================] - 3s 286us/step - loss: 0.0902 - accuracy: 0.9725\n",
      "Epoch 24/100\n",
      "8844/8844 [==============================] - 3s 285us/step - loss: 0.1018 - accuracy: 0.9708\n",
      "Epoch 25/100\n",
      "8844/8844 [==============================] - 3s 290us/step - loss: 0.0916 - accuracy: 0.9713\n",
      "Epoch 26/100\n",
      "8844/8844 [==============================] - 2s 281us/step - loss: 0.0727 - accuracy: 0.9734\n",
      "2211/2211 [==============================] - 0s 49us/step\n",
      "\n",
      "Accuracy score of the Neural Network with learning rate modified 94.89%\n"
     ]
    }
   ],
   "source": [
    "history_TDLHBA = model_TDLHBA.fit(x_train, y_train, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores = model_TDLHBA.evaluate(x_test, y_test)\n",
    "print('\\nAccuracy score of the Neural Network with learning rate modified {0:.2f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modifying Learning Rate on Dataset #2 Neural Network\n",
    "\n",
    "Learning Rate | Result\n",
    "--- | ---\n",
    "0.01 | 65.49%\n",
    "0.0002 | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_TDLHBA2 = Sequential()\n",
    "\n",
    "model_TDLHBA2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform',input_dim=x2.shape[1]))\n",
    "model_TDLHBA2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA2.add(Dense(150, activation='relu',\n",
    "          kernel_initializer='uniform'))\n",
    "model_TDLHBA2.add(Dense(1,  activation='sigmoid', \n",
    "          kernel_initializer='uniform'))\n",
    "\n",
    "adam = Adam(lr=0.0002)\n",
    "model_TDLHBA2.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "70917/70917 [==============================] - 24s 345us/step - loss: 0.3691 - accuracy: 0.8277\n",
      "Epoch 2/100\n",
      "70917/70917 [==============================] - 22s 311us/step - loss: 0.2461 - accuracy: 0.8995\n",
      "Epoch 3/100\n",
      "70917/70917 [==============================] - 23s 319us/step - loss: 0.2272 - accuracy: 0.9054\n",
      "Epoch 4/100\n",
      "70917/70917 [==============================] - 24s 341us/step - loss: 0.2169 - accuracy: 0.9098\n",
      "Epoch 5/100\n",
      "70917/70917 [==============================] - 27s 375us/step - loss: 0.2107 - accuracy: 0.9116\n",
      "Epoch 6/100\n",
      "70917/70917 [==============================] - 25s 356us/step - loss: 0.2052 - accuracy: 0.9143\n",
      "Epoch 7/100\n",
      "70917/70917 [==============================] - 26s 362us/step - loss: 0.1977 - accuracy: 0.9176\n",
      "Epoch 8/100\n",
      "70917/70917 [==============================] - 27s 379us/step - loss: 0.1937 - accuracy: 0.9202\n",
      "Epoch 9/100\n",
      "70917/70917 [==============================] - 26s 360us/step - loss: 0.1877 - accuracy: 0.9232\n",
      "Epoch 10/100\n",
      "70917/70917 [==============================] - 28s 397us/step - loss: 0.1866 - accuracy: 0.9233\n",
      "Epoch 11/100\n",
      "70917/70917 [==============================] - 31s 432us/step - loss: 0.1843 - accuracy: 0.9245\n",
      "Epoch 12/100\n",
      "70917/70917 [==============================] - 33s 459us/step - loss: 0.1816 - accuracy: 0.9252\n",
      "Epoch 13/100\n",
      "70917/70917 [==============================] - 40s 568us/step - loss: 0.1801 - accuracy: 0.9258\n",
      "Epoch 14/100\n",
      "70917/70917 [==============================] - 53s 753us/step - loss: 0.1773 - accuracy: 0.9273\n",
      "Epoch 15/100\n",
      "70917/70917 [==============================] - 38s 533us/step - loss: 0.1767 - accuracy: 0.9275\n",
      "Epoch 16/100\n",
      "70917/70917 [==============================] - 45s 633us/step - loss: 0.1760 - accuracy: 0.9276\n",
      "Epoch 17/100\n",
      "70917/70917 [==============================] - 62s 873us/step - loss: 0.1712 - accuracy: 0.9299\n",
      "Epoch 18/100\n",
      "70917/70917 [==============================] - 50s 701us/step - loss: 0.1707 - accuracy: 0.9305\n",
      "Epoch 19/100\n",
      "70917/70917 [==============================] - 37s 528us/step - loss: 0.1680 - accuracy: 0.9332\n",
      "Epoch 20/100\n",
      "70917/70917 [==============================] - 40s 564us/step - loss: 0.1677 - accuracy: 0.9342\n",
      "Epoch 21/100\n",
      "70917/70917 [==============================] - 40s 560us/step - loss: 0.1657 - accuracy: 0.9351\n",
      "Epoch 22/100\n",
      "70917/70917 [==============================] - 37s 517us/step - loss: 0.1669 - accuracy: 0.9340\n",
      "Epoch 23/100\n",
      "70917/70917 [==============================] - 51s 714us/step - loss: 0.1658 - accuracy: 0.9347\n",
      "Epoch 24/100\n",
      "70917/70917 [==============================] - 43s 603us/step - loss: 0.1645 - accuracy: 0.9360\n",
      "Epoch 25/100\n",
      "70917/70917 [==============================] - 39s 550us/step - loss: 0.1652 - accuracy: 0.9371\n",
      "Epoch 26/100\n",
      "70917/70917 [==============================] - 40s 570us/step - loss: 0.1648 - accuracy: 0.9359\n",
      "Epoch 27/100\n",
      "70917/70917 [==============================] - 38s 537us/step - loss: 0.1613 - accuracy: 0.9362\n",
      "Epoch 28/100\n",
      "70917/70917 [==============================] - 38s 538us/step - loss: 0.1601 - accuracy: 0.9367\n",
      "Epoch 29/100\n",
      "70917/70917 [==============================] - 38s 538us/step - loss: 0.1593 - accuracy: 0.9377\n",
      "Epoch 30/100\n",
      "70917/70917 [==============================] - 46s 648us/step - loss: 0.1592 - accuracy: 0.9385\n",
      "Epoch 31/100\n",
      "70917/70917 [==============================] - 39s 552us/step - loss: 0.1579 - accuracy: 0.9386\n",
      "Epoch 32/100\n",
      "70917/70917 [==============================] - 49s 695us/step - loss: 0.1593 - accuracy: 0.9376\n",
      "Epoch 33/100\n",
      "70917/70917 [==============================] - 43s 603us/step - loss: 0.1560 - accuracy: 0.9392\n",
      "Epoch 34/100\n",
      "70917/70917 [==============================] - 39s 544us/step - loss: 0.1598 - accuracy: 0.9388\n",
      "Epoch 35/100\n",
      "70917/70917 [==============================] - 43s 603us/step - loss: 0.1548 - accuracy: 0.9401\n",
      "Epoch 36/100\n",
      " 7720/70917 [==>...........................] - ETA: 48s - loss: 0.1592 - accuracy: 0.9394"
     ]
    }
   ],
   "source": [
    "history_TDLHBA2 = model_TDLHBA2.fit(x_train2, y_train2, batch_size=10, epochs=100, verbose=1, callbacks=[es_cb])\n",
    "\n",
    "scores2 = model_TDLHBA2.evaluate(x_test2, y_test2)\n",
    "print('\\nAccuracy score of the Neural Network with learning rate modified {0:.2f}%'.format(scores2[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
